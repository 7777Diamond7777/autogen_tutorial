{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Gen Tutorial\n",
    "Note book written by John Adeojo\n",
    "Founder, and Chief Data Scientist at [Data-centric Solutions](https://www.data-centric-solutions.com/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "import yaml\n",
    "import openai \n",
    "import os\n",
    "\n",
    "script_dir = \"C:/Users/johna/OneDrive/Documents/api_keys/\"\n",
    "index_path = \"G:/My Drive/Data-Centric Solutions/07. Blog Posts/AutoGen/autogen_tutorial/indexes/\"\n",
    "configurations_path = \"G:/My Drive/Data-Centric Solutions/07. Blog Posts/AutoGen/autogen_tutorial/\"\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file=\"configurations.json\",\n",
    "    file_location=configurations_path,\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4-1106-preview\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "def get_apikey(script_dir=script_dir):\n",
    "\n",
    "    script_dir = script_dir\n",
    "    file_path = os.path.join(script_dir, \"apikeys.yml\")\n",
    "\n",
    "    with open(file_path, 'r') as yamlfile:\n",
    "        loaded_yamlfile = yaml.safe_load(yamlfile)\n",
    "        API_KEY = loaded_yamlfile['openai']['api_key']\n",
    "\n",
    "    return API_KEY\n",
    "\n",
    "openai.api_key = get_apikey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List\n",
    "\n",
    "from llama_index.readers.base import BaseReader\n",
    "from llama_index.readers.schema.base import Document\n",
    "import wikipedia\n",
    "\n",
    "class WikipediaReader(BaseReader):\n",
    "    def load_data(self, pages: List[str], lang: str = \"en\", **load_kwargs: Any) -> List[Document]:\n",
    "        results = []\n",
    "        for page in pages:\n",
    "            wikipedia.set_lang(lang)\n",
    "            wiki_page = wikipedia.page(page, **load_kwargs)\n",
    "            page_content = wiki_page.content\n",
    "            page_url = wiki_page.url\n",
    "            # Create a Document with URL included in the metadata\n",
    "            document = Document(text=page_content, metadata={'source_url': page_url})\n",
    "            results.append(document)\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool 1: Does a query based search for Wikipages\n",
    "import wikipedia\n",
    "from llama_index import download_loader, VectorStoreIndex, ServiceContext\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.text_splitter import get_default_text_splitter\n",
    "from llama_index import StorageContext\n",
    "from llama_index import load_index_from_storage\n",
    "import json\n",
    "\n",
    "def load_index(filepath: str):\n",
    "    # rebuild storage context\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=index_path)\n",
    "    # load index\n",
    "    return load_index_from_storage(storage_context)\n",
    "\n",
    "def read_json_file(file_path: str) -> dict:\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_wikidocs(wikipage_requests):\n",
    "    print(f\"Preparing to Download:{wikipage_requests}\")\n",
    "    documents = []\n",
    "    for page_title in wikipage_requests:\n",
    "        try:\n",
    "            # Attempt to load the Wikipedia page\n",
    "            wiki_page = wikipedia.page(page_title)\n",
    "            page_content = wiki_page.content\n",
    "            page_url = wiki_page.url\n",
    "            document = Document(text=page_content, metadata={'source_url': page_url})\n",
    "            documents.append(document)\n",
    "        except wikipedia.exceptions.PageError:\n",
    "            # Handle the case where the page does not exist\n",
    "            print(f\"PageError: The page titled '{page_title}' does not exist on Wikipedia.\")\n",
    "        except wikipedia.exceptions.DisambiguationError as e:\n",
    "            # Handle the case where the page title is ambiguous\n",
    "            print(f\"DisambiguationError: The page titled '{page_title}' is ambiguous. Possible options: {e.options}\")\n",
    "    print(\"Finished downloading pages\")\n",
    "    return documents\n",
    "\n",
    "\n",
    "def index_wikipedia_pages(wikipage_requests):\n",
    "    print(f\"Preparing to index Wikipages: {wikipage_requests}\")\n",
    "    documents = create_wikidocs(wikipage_requests)\n",
    "    text_splits = get_default_text_splitter(chunk_size=150, chunk_overlap=45)\n",
    "    parser = SimpleNodeParser.from_defaults(text_splitter=text_splits)\n",
    "    service_context = ServiceContext.from_defaults(node_parser=parser)\n",
    "    index =  VectorStoreIndex.from_documents(documents, service_context=service_context, show_progress=False)\n",
    "    index.storage_context.persist(index_path)\n",
    "    print(f\"{wikipage_requests} have been indexed.\")\n",
    "    return \"indexed\"\n",
    "\n",
    "def search_and_index_wikipedia(\n",
    "        hops: list, lang: str = \"en\", results_limit: int = 2\n",
    "    ):\n",
    "\n",
    "    # Set the language for Wikipedia\n",
    "    wikipedia.set_lang(lang)\n",
    "\n",
    "    # Initialize an empty list to hold all indexed page titles\n",
    "    wikipage_requests = []\n",
    "\n",
    "    # Loop through the identified hops and search for each\n",
    "    for hop in hops:\n",
    "        hop_pages = wikipedia.search(hop, results=results_limit)\n",
    "        print(f\"Searching Wikipedia for: {hop} - Found: {hop_pages}\")\n",
    "        wikipage_requests.extend(hop_pages)\n",
    "\n",
    "    # Index the gathered pages (assuming 'index_wikipedia_pages' is a defined function that you implement)\n",
    "    index_wikipedia_pages(wikipage_requests)\n",
    "\n",
    "    return wikipage_requests\n",
    "\n",
    "\n",
    "def query_wiki_index(hops: List[str], index_path: str = index_path, n_results: int = 5): \n",
    "    index = load_index(filepath=index_path)\n",
    "    query_engine = index.as_query_engine(\n",
    "        response_mode=\"compact\", verbose=True, similarity_top_k=n_results\n",
    "    )\n",
    "    \n",
    "    retrieved_context = {}\n",
    "    \n",
    "    # Iterate over each hop in the multihop query\n",
    "    for hop in hops:\n",
    "        nodes = query_engine.query(hop).source_nodes\n",
    "        \n",
    "        # Process each node found for the current hop\n",
    "        for node in nodes:\n",
    "            doc_id = node.node.id_\n",
    "            doc_text = node.node.text\n",
    "            doc_source = node.node.metadata.get('source_url', 'No source URL')  # Default value if source_url is not present.\n",
    "            \n",
    "            # Append to the list of texts and sources for each doc_id\n",
    "            if doc_id not in retrieved_context:\n",
    "                retrieved_context[doc_id] = {'texts': [doc_text], 'sources': [doc_source]}\n",
    "            else:\n",
    "                retrieved_context[doc_id]['texts'].append(doc_text)\n",
    "                retrieved_context[doc_id]['sources'].append(doc_source)\n",
    "\n",
    "    # Serialise the context for all hops into a JSON file\n",
    "    file_path = index_path + \"retrieved_context.json\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(retrieved_context, f)\n",
    "    \n",
    "    return retrieved_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm_config = {\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"search_and_index_wikipedia\",\n",
    "            \"description\": \"Indexes Wikipedia pages based on specified queries for each hop to build a knowledge base for future reference. Use before query_wiki_index.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"hops\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"description\": \"The search queries for identifying relevant Wikipedia pages to index, each corresponding to a hop in the multihop question.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"hops\"],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"query_wiki_index\",\n",
    "            \"description\": \"Queries the indexed Wikipedia knowledge base to retrieve pertinent information across multiple hops\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"hops\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"description\": \"The search queries to search the indexed Wikipedia knowledge base for relevant information, each corresponding to a hop in the multihop question.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"hops\"],\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "    \"config_list\": config_list,\n",
    "    \"request_timeout\": 120,\n",
    "    \"seed\": 100,\n",
    "    \"temperature\":0.7\n",
    "}\n",
    "\n",
    "# The llm_config_no_tools remains the same, excluding the 'functions' key.\n",
    "llm_config_no_tools = {k: v for k, v in llm_config.items() if k != 'functions'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "What were the key points raised in the 2023 AI safety Summit?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33manalyst\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: search_and_index_wikipedia *****\u001b[0m\n",
      "Arguments: \n",
      "{\"hops\":[\"2023 AI safety Summit\",\"key points 2023 AI safety Summit\"]}\n",
      "\u001b[32m***************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION search_and_index_wikipedia...\u001b[0m\n",
      "Searching Wikipedia for: 2023 AI safety Summit - Found: ['2023 AI Safety Summit', 'AI safety']\n",
      "Searching Wikipedia for: key points 2023 AI safety Summit - Found: ['2023 AI Safety Summit', 'Regulation of artificial intelligence']\n",
      "Preparing to index Wikipages: ['2023 AI Safety Summit', 'AI safety', '2023 AI Safety Summit', 'Regulation of artificial intelligence']\n",
      "Preparing to Download:['2023 AI Safety Summit', 'AI safety', '2023 AI Safety Summit', 'Regulation of artificial intelligence']\n",
      "Finished downloading pages\n",
      "['2023 AI Safety Summit', 'AI safety', '2023 AI Safety Summit', 'Regulation of artificial intelligence'] have been indexed.\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"search_and_index_wikipedia\" *****\u001b[0m\n",
      "['2023 AI Safety Summit', 'AI safety', '2023 AI Safety Summit', 'Regulation of artificial intelligence']\n",
      "\u001b[32m***********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33manalyst\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: query_wiki_index *****\u001b[0m\n",
      "Arguments: \n",
      "{\"hops\":[\"2023 AI safety Summit\",\"key points 2023 AI safety Summit\"]}\n",
      "\u001b[32m*****************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION query_wiki_index...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"query_wiki_index\" *****\u001b[0m\n",
      "{'c7c19b35-09d7-465c-a18c-69af1679e0d5': {'texts': ['The 2023 Artificial Intelligence Safety Summit was an international conference discussing the safety and regulation of artificial intelligence. It was held at Bletchley Park, Milton Keynes, United Kingdom, on 1–2 November 2023. It was the first ever global summit on artificial intelligence.\\n\\n\\n== Background ==\\nPrime Minister of the United Kingdom Rishi Sunak has made AI one of the priorities of his government, announcing that the UK would host a global AI Safety conference in Autumn 2023.', 'The 2023 Artificial Intelligence Safety Summit was an international conference discussing the safety and regulation of artificial intelligence. It was held at Bletchley Park, Milton Keynes, United Kingdom, on 1–2 November 2023. It was the first ever global summit on artificial intelligence.\\n\\n\\n== Background ==\\nPrime Minister of the United Kingdom Rishi Sunak has made AI one of the priorities of his government, announcing that the UK would host a global AI Safety conference in Autumn 2023.'], 'sources': ['https://en.wikipedia.org/wiki/2023_AI_Safety_Summit', 'https://en.wikipedia.org/wiki/2023_AI_Safety_Summit']}, 'd2816e57-9349-4957-ba7a-d313434a0e1f': {'texts': ['The 2023 Artificial Intelligence Safety Summit was an international conference discussing the safety and regulation of artificial intelligence. It was held at Bletchley Park, Milton Keynes, United Kingdom, on 1–2 November 2023. It was the first ever global summit on artificial intelligence.\\n\\n\\n== Background ==\\nPrime Minister of the United Kingdom Rishi Sunak has made AI one of the priorities of his government, announcing that the UK would host a global AI Safety conference in Autumn 2023.', 'The 2023 Artificial Intelligence Safety Summit was an international conference discussing the safety and regulation of artificial intelligence. It was held at Bletchley Park, Milton Keynes, United Kingdom, on 1–2 November 2023. It was the first ever global summit on artificial intelligence.\\n\\n\\n== Background ==\\nPrime Minister of the United Kingdom Rishi Sunak has made AI one of the priorities of his government, announcing that the UK would host a global AI Safety conference in Autumn 2023.'], 'sources': ['https://en.wikipedia.org/wiki/2023_AI_Safety_Summit', 'https://en.wikipedia.org/wiki/2023_AI_Safety_Summit']}, '70482b12-4161-4a05-bcdc-74ebc24cce66': {'texts': ['The US Government also announced the creation of an American AI Safety Institute, as part of the National Institute of Standards and Technology.\\n\\n\\n== Future ==\\nThe next AI Safety Summit is planned to be hosted by South Korea in mid-2024, followed by France around late-2024.\\n\\n\\n== Notable attendees ==\\nThe following individuals are expected to attend the summit:\\n\\nRishi Sunak, prime minister of the United Kingdom\\nKamala Harris, vice president of the United States\\nCharles III, king of the United Kingdom (attending virtually)\\nElon Musk, CEO of Tesla,', 'The US Government also announced the creation of an American AI Safety Institute, as part of the National Institute of Standards and Technology.\\n\\n\\n== Future ==\\nThe next AI Safety Summit is planned to be hosted by South Korea in mid-2024, followed by France around late-2024.\\n\\n\\n== Notable attendees ==\\nThe following individuals are expected to attend the summit:\\n\\nRishi Sunak, prime minister of the United Kingdom\\nKamala Harris, vice president of the United States\\nCharles III, king of the United Kingdom (attending virtually)\\nElon Musk, CEO of Tesla,'], 'sources': ['https://en.wikipedia.org/wiki/2023_AI_Safety_Summit', 'https://en.wikipedia.org/wiki/2023_AI_Safety_Summit']}, '4996623f-42c2-43df-9019-9cc2635eba3a': {'texts': ['The US Government also announced the creation of an American AI Safety Institute, as part of the National Institute of Standards and Technology.\\n\\n\\n== Future ==\\nThe next AI Safety Summit is planned to be hosted by South Korea in mid-2024, followed by France around late-2024.\\n\\n\\n== Notable attendees ==\\nThe following individuals are expected to attend the summit:\\n\\nRishi Sunak, prime minister of the United Kingdom\\nKamala Harris, vice president of the United States\\nCharles III, king of the United Kingdom (attending virtually)\\nElon Musk, CEO of Tesla,', 'The US Government also announced the creation of an American AI Safety Institute, as part of the National Institute of Standards and Technology.\\n\\n\\n== Future ==\\nThe next AI Safety Summit is planned to be hosted by South Korea in mid-2024, followed by France around late-2024.\\n\\n\\n== Notable attendees ==\\nThe following individuals are expected to attend the summit:\\n\\nRishi Sunak, prime minister of the United Kingdom\\nKamala Harris, vice president of the United States\\nCharles III, king of the United Kingdom (attending virtually)\\nElon Musk, CEO of Tesla,'], 'sources': ['https://en.wikipedia.org/wiki/2023_AI_Safety_Summit', 'https://en.wikipedia.org/wiki/2023_AI_Safety_Summit']}, 'a1f2a58a-f6f4-4af7-aab2-2c7c2dc14c3a': {'texts': ['== Agenda ==\\nTech entrepreneur Elon Musk and Prime Minister Rishi Sunak did a live interview on AI safety on 2 November on X.\\n\\n\\n== Outcomes ==\\n28 countries at the summit, including the United States, China, and the European Union, have issued an agreement known as the \"Bletchley Declaration\", calling for international co-operation to manage the challenges and risks of artificial intelligence. Emphasis has been placed on regulating \"Frontier AI\", a term for the latest and most powerful AI systems.', '== Agenda ==\\nTech entrepreneur Elon Musk and Prime Minister Rishi Sunak did a live interview on AI safety on 2 November on X.\\n\\n\\n== Outcomes ==\\n28 countries at the summit, including the United States, China, and the European Union, have issued an agreement known as the \"Bletchley Declaration\", calling for international co-operation to manage the challenges and risks of artificial intelligence. Emphasis has been placed on regulating \"Frontier AI\", a term for the latest and most powerful AI systems.'], 'sources': ['https://en.wikipedia.org/wiki/2023_AI_Safety_Summit', 'https://en.wikipedia.org/wiki/2023_AI_Safety_Summit']}}\n",
      "\u001b[32m*************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mreporter\u001b[0m (to chat_manager):\n",
      "\n",
      "The 2023 AI Safety Summit was a significant event that marked the first-ever global summit on artificial intelligence safety and regulation. It took place at Bletchley Park in Milton Keynes, United Kingdom, on the 1st and 2nd of November 2023. The Prime Minister of the United Kingdom, Rishi Sunak, had declared AI as one of the priorities of his government and announced the hosting of this conference[1].\n",
      "\n",
      "During the summit, the US Government announced the creation of an American AI Safety Institute as part of the National Institute of Standards and Technology. Notable attendees included Rishi Sunak, Kamala Harris, the Vice President of the United States, Charles III (who attended virtually), and Elon Musk, the CEO of Tesla[2].\n",
      "\n",
      "A key outcome of the summit was the \"Bletchley Declaration,\" which was issued by 28 countries, including the United States, China, and the European Union. This declaration called for international cooperation to manage the challenges and risks associated with artificial intelligence, with a particular emphasis on regulating \"Frontier AI,\" which refers to the latest and most powerful AI systems[3].\n",
      "\n",
      "Additionally, Elon Musk and Prime Minister Rishi Sunak conducted a live interview on AI safety on the 2nd of November, further highlighting the importance of the topic[3].\n",
      "\n",
      "The summit set a precedent for future events, with the next AI Safety Summit planned to be hosted by South Korea in mid-2024, followed by France in late-2024[2].\n",
      "\n",
      "References\n",
      "1. Wikipedia. Available from: https://en.wikipedia.org/wiki/2023_AI_Safety_Summit\n",
      "2. Wikipedia. Available from: https://en.wikipedia.org/wiki/2023_AI_Safety_Summit\n",
      "3. Wikipedia. Available from: https://en.wikipedia.org/wiki/2023_AI_Safety_Summit\n",
      "\n",
      "PLEASE REVIEW\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mmoderator\u001b[0m (to chat_manager):\n",
      "\n",
      "The answer is approved.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import autogen \n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=5,\n",
    "    # system_message='''You should start the workflow by consulting the analyst, then the reporter and finally the moderator. \n",
    "    # If the analyst does not use both the `search_and_index_wikipedia` and the `query_wiki_index`, you must request that it does.'''\n",
    "    \n",
    ")\n",
    "\n",
    "analyst = autogen.AssistantAgent(\n",
    "    name=\"analyst\",\n",
    "    system_message='''\n",
    "    As the Information Gatherer, you must start by using the `search_and_index_wikipedia` function to gather relevant data about the user's query. Follow these steps:\n",
    "\n",
    "    1. Upon receiving a query, immediately invoke the `search_and_index_wikipedia` function to find and index Wikipedia pages related to the query. Do not proceed without completing this step.\n",
    "    2. After successfully indexing, utilize the `query_wiki_index` to extract detailed information from the indexed content.\n",
    "    3. Present the indexed information and detailed findings to the Reporter, ensuring they have a comprehensive dataset to draft a response.\n",
    "    4. Conclude your part with \"INFORMATION GATHERING COMPLETE\" to signal that you have finished collecting data and it is now ready for the Reporter to use in formulating the answer.\n",
    "\n",
    "    Remember, you are responsible for information collection and indexing only. The Reporter will rely on the accuracy and completeness of your findings to generate the final answer.\n",
    "\n",
    "    ''',\n",
    "    llm_config=llm_config,\n",
    "    # human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "reporter = autogen.AssistantAgent(\n",
    "    name=\"reporter\",\n",
    "    system_message='''\n",
    "    As the Reporter, you are responsible for formulating an answer to the user's query using the information provided by the Information Gatherer.\n",
    "\n",
    "    1. Wait for the Information Gatherer to complete their task and present you with the indexed information.\n",
    "    2. Using the gathered data, create a comprehensive and precise response that adheres to the criteria of precision, depth, clarity, and proper citation.\n",
    "    3. Present your draft answer followed by \"PLEASE REVIEW\" for the Moderator to assess.\n",
    "\n",
    "    If the Moderator approves your answer, conclude with \"TERMINATE\" to signal the end of the interaction.\n",
    "\n",
    "    If the Moderator rejects your answer:\n",
    "    - Review their feedback.\n",
    "    - Make necessary amendments.\n",
    "    - Resubmit the revised answer with \"PLEASE REVIEW.\"\n",
    "\n",
    "    Ensure that your response is fully informed by the data provided and meets the established criteria.\n",
    "\n",
    "    criteria are as follows:\n",
    "     A. Precision: Directly address the user's question.\n",
    "     B. Depth: Provide comprehensive information using indexed content.\n",
    "     C. Citing: Incorporate citations within your response using the Vancouver citation style. \n",
    "     For each reference, a superscript number shoud be insered in the text at the point of citation, corresponding to the number of the reference. \n",
    "     At the end of the document, references must be listed numerically with links to the source provided. \n",
    "     For instance, if you are citing a Wikipedia article, it would look like this in the text:\n",
    "\n",
    "        \"The collapse of Silicon Valley Bank was primarily due to...[1].\"\n",
    "\n",
    "        And then at the end of the document:\n",
    "\n",
    "        References\n",
    "        1. Wikipedia Available from: https://en.wikipedia.org/wiki/Collapse_of_Silicon_Valley_Bank.\n",
    "\n",
    "        Ensure that each citation number corresponds to a unique reference which is listed at the end of your report in the order they appear in the text.\n",
    "          D. Clarity: Present information logically and coherently.\n",
    "\n",
    "    ''',\n",
    "    llm_config=llm_config_no_tools,\n",
    "    \n",
    "    # human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "moderator = autogen.AssistantAgent(\n",
    "    name=\"moderator\",\n",
    "    system_message='''\n",
    "\n",
    "    As the Moderator, your task is to review the Reporter's answers to ensure they meet the required criteria:\n",
    "\n",
    "    - Assess the Reporter's answers after the \"PLEASE REVIEW\" prompt for alignment with the following criteria:\n",
    "     A. Precision: Directly addressed the user's question.\n",
    "     B. Depth: Provided comprehensive information using indexed content.\n",
    "     C. Citing: Citations should be encorporated using the Vancouver citation style. \n",
    "     For each reference, a superscript number shoud be insered in the text at the point of citation, corresponding to the number of the reference. \n",
    "     At the end of the document, references must be listed numerically with links to the source provided. \n",
    "     For instance, if you are citing a Wikipedia article, it would look like this in the text:\n",
    "\n",
    "        \"The collapse of Silicon Valley Bank was primarily due to...[1].\"\n",
    "\n",
    "        And then at the end of the document:\n",
    "\n",
    "        References\n",
    "        1. Wikipedia Available from: https://en.wikipedia.org/wiki/Collapse_of_Silicon_Valley_Bank.\n",
    "\n",
    "        Ensure that each citation number corresponds to a unique reference which is listed at the end of your report in the order they appear in the text.\n",
    "     \n",
    "     D. Clarity: information presented logically and coherently.\n",
    "    - Approve the answer by stating \"The answer is approved\" if it meets the criteria.\n",
    "    - If the answer falls short, specify which criteria were not met and instruct the Reporter to revise the answer accordingly. Do not generate new content or answers yourself.\n",
    "\n",
    "    Your role is crucial in ensuring that the final answer provided to the user is factually correct and meets all specified quality standards.\n",
    "\n",
    "    ''',\n",
    "    llm_config=llm_config_no_tools,\n",
    "    # human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "user_proxy.register_function(\n",
    "    function_map={\n",
    "        \"search_and_index_wikipedia\": search_and_index_wikipedia,\n",
    "        \"query_wiki_index\":query_wiki_index,\n",
    "        # \"generate_response\":generate_response\n",
    "    }\n",
    ")\n",
    "\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, analyst, reporter, moderator], messages=[], max_round=20)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, \n",
    "                                   llm_config=llm_config, \n",
    "                                   system_message='''You should start the workflow by consulting the analyst, then the reporter and finally the moderator. \n",
    "    If the analyst does not use both the `search_and_index_wikipedia` and the `query_wiki_index`, you must request that it does.''')\n",
    "user_proxy.initiate_chat(\n",
    "    manager, \n",
    "    message='''What were the key points raised in the 2023 AI safety Summit?'''\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
