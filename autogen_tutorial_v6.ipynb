{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Gen Tutorial\n",
    "Note book written by John Adeojo\n",
    "Founder, and Chief Data Scientist at [Data-centric Solutions](https://www.data-centric-solutions.com/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "import yaml\n",
    "import openai \n",
    "import os\n",
    "\n",
    "script_dir = \"C:/Users/johna/OneDrive/Documents/api_keys/\"\n",
    "index_path = \"G:/My Drive/Data-Centric Solutions/07. Blog Posts/AutoGen/autogen_tutorial/indexes/\"\n",
    "configurations_path = \"G:/My Drive/Data-Centric Solutions/07. Blog Posts/AutoGen/autogen_tutorial/\"\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file=\"configurations.json\",\n",
    "    file_location=configurations_path,\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4-1106-preview\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "def get_apikey(script_dir=script_dir):\n",
    "\n",
    "    script_dir = script_dir\n",
    "    file_path = os.path.join(script_dir, \"apikeys.yml\")\n",
    "\n",
    "    with open(file_path, 'r') as yamlfile:\n",
    "        loaded_yamlfile = yaml.safe_load(yamlfile)\n",
    "        API_KEY = loaded_yamlfile['openai']['api_key']\n",
    "\n",
    "    return API_KEY\n",
    "\n",
    "openai.api_key = get_apikey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List\n",
    "\n",
    "from llama_index.readers.base import BaseReader\n",
    "from llama_index.readers.schema.base import Document\n",
    "import wikipedia\n",
    "\n",
    "class WikipediaReader(BaseReader):\n",
    "    def load_data(self, pages: List[str], lang: str = \"en\", **load_kwargs: Any) -> List[Document]:\n",
    "        results = []\n",
    "        for page in pages:\n",
    "            wikipedia.set_lang(lang)\n",
    "            wiki_page = wikipedia.page(page, **load_kwargs)\n",
    "            page_content = wiki_page.content\n",
    "            page_url = wiki_page.url\n",
    "            # Create a Document with URL included in the metadata\n",
    "            document = Document(text=page_content, metadata={'source_url': page_url})\n",
    "            results.append(document)\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool 1: Does a query based search for Wikipages\n",
    "import wikipedia\n",
    "from llama_index import download_loader, VectorStoreIndex, ServiceContext\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.text_splitter import get_default_text_splitter\n",
    "from llama_index import StorageContext\n",
    "from llama_index import load_index_from_storage\n",
    "import json\n",
    "\n",
    "def load_index(filepath: str):\n",
    "    # rebuild storage context\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=index_path)\n",
    "    # load index\n",
    "    return load_index_from_storage(storage_context)\n",
    "\n",
    "def read_json_file(file_path: str) -> dict:\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_wikidocs(wikipage_requests):\n",
    "    print(f\"Preparing to Download:{wikipage_requests}\")\n",
    "    documents = []\n",
    "    for page_title in wikipage_requests:\n",
    "        try:\n",
    "            # Attempt to load the Wikipedia page\n",
    "            wiki_page = wikipedia.page(page_title)\n",
    "            page_content = wiki_page.content\n",
    "            page_url = wiki_page.url\n",
    "            document = Document(text=page_content, metadata={'source_url': page_url})\n",
    "            documents.append(document)\n",
    "        except wikipedia.exceptions.PageError:\n",
    "            # Handle the case where the page does not exist\n",
    "            print(f\"PageError: The page titled '{page_title}' does not exist on Wikipedia.\")\n",
    "        except wikipedia.exceptions.DisambiguationError as e:\n",
    "            # Handle the case where the page title is ambiguous\n",
    "            print(f\"DisambiguationError: The page titled '{page_title}' is ambiguous. Possible options: {e.options}\")\n",
    "    print(\"Finished downloading pages\")\n",
    "    return documents\n",
    "\n",
    "\n",
    "def index_wikipedia_pages(wikipage_requests):\n",
    "    print(f\"Preparing to index Wikipages: {wikipage_requests}\")\n",
    "    documents = create_wikidocs(wikipage_requests)\n",
    "    text_splits = get_default_text_splitter(chunk_size=150, chunk_overlap=45)\n",
    "    parser = SimpleNodeParser.from_defaults(text_splitter=text_splits)\n",
    "    service_context = ServiceContext.from_defaults(node_parser=parser)\n",
    "    index =  VectorStoreIndex.from_documents(documents, service_context=service_context, show_progress=False)\n",
    "    index.storage_context.persist(index_path)\n",
    "    print(f\"{wikipage_requests} have been indexed.\")\n",
    "    return \"indexed\"\n",
    "\n",
    "def search_and_index_wikipedia(\n",
    "        hops: list, lang: str = \"en\", results_limit: int = 2\n",
    "    ):\n",
    "\n",
    "    # Set the language for Wikipedia\n",
    "    wikipedia.set_lang(lang)\n",
    "\n",
    "    # Initialize an empty list to hold all indexed page titles\n",
    "    wikipage_requests = []\n",
    "\n",
    "    # Loop through the identified hops and search for each\n",
    "    for hop in hops:\n",
    "        hop_pages = wikipedia.search(hop, results=results_limit)\n",
    "        print(f\"Searching Wikipedia for: {hop} - Found: {hop_pages}\")\n",
    "        wikipage_requests.extend(hop_pages)\n",
    "\n",
    "    # Index the gathered pages (assuming 'index_wikipedia_pages' is a defined function that you implement)\n",
    "    index_wikipedia_pages(wikipage_requests)\n",
    "\n",
    "    return wikipage_requests\n",
    "\n",
    "\n",
    "def query_wiki_index(hops: List[str], index_path: str = index_path, n_results: int = 5): \n",
    "    index = load_index(filepath=index_path)\n",
    "    query_engine = index.as_query_engine(\n",
    "        response_mode=\"compact\", verbose=True, similarity_top_k=n_results\n",
    "    )\n",
    "    \n",
    "    retrieved_context = {}\n",
    "    \n",
    "    # Iterate over each hop in the multihop query\n",
    "    for hop in hops:\n",
    "        nodes = query_engine.query(hop).source_nodes\n",
    "        \n",
    "        # Process each node found for the current hop\n",
    "        for node in nodes:\n",
    "            doc_id = node.node.id_\n",
    "            doc_text = node.node.text\n",
    "            doc_source = node.node.metadata.get('source_url', 'No source URL')  # Default value if source_url is not present.\n",
    "            \n",
    "            # Append to the list of texts and sources for each doc_id\n",
    "            if doc_id not in retrieved_context:\n",
    "                retrieved_context[doc_id] = {'texts': [doc_text], 'sources': [doc_source]}\n",
    "            else:\n",
    "                retrieved_context[doc_id]['texts'].append(doc_text)\n",
    "                retrieved_context[doc_id]['sources'].append(doc_source)\n",
    "\n",
    "    # Serialise the context for all hops into a JSON file\n",
    "    file_path = index_path + \"retrieved_context.json\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(retrieved_context, f)\n",
    "    \n",
    "    return retrieved_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm_config = {\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"search_and_index_wikipedia\",\n",
    "            \"description\": \"Indexes Wikipedia pages based on specified queries for each hop to build a knowledge base for future reference. Use before query_wiki_index.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"hops\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"description\": \"The search queries for identifying relevant Wikipedia pages to index, each corresponding to a hop in the multihop question.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"hops\"],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"query_wiki_index\",\n",
    "            \"description\": \"Queries the indexed Wikipedia knowledge base to retrieve pertinent information across multiple hops\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"hops\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"description\": \"The search queries to search the indexed Wikipedia knowledge base for relevant information, each corresponding to a hop in the multihop question.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"hops\"],\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "    \"config_list\": config_list,\n",
    "    \"request_timeout\": 120,\n",
    "    \"seed\": 100,\n",
    "    \"temperature\":0.7\n",
    "}\n",
    "\n",
    "# The llm_config_no_tools remains the same, excluding the 'functions' key.\n",
    "llm_config_no_tools = {k: v for k, v in llm_config.items() if k != 'functions'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "What happened in Israel on the 7th October 2023 and what was Biden's response?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: search_and_index_wikipedia *****\u001b[0m\n",
      "Arguments: \n",
      "{\"hops\":[\"Israel 7th October 2023\",\"Joe Biden response October 2023\"]}\n",
      "\u001b[32m***************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION search_and_index_wikipedia...\u001b[0m\n",
      "Searching Wikipedia for: Israel 7th October 2023 - Found: ['2023 Israel–Hamas war', '2023 Hamas attack on Israel']\n",
      "Searching Wikipedia for: Joe Biden response October 2023 - Found: ['Joe Biden', 'Timeline of the Joe Biden presidency (2023 Q4)']\n",
      "Preparing to index Wikipages: ['2023 Israel–Hamas war', '2023 Hamas attack on Israel', 'Joe Biden', 'Timeline of the Joe Biden presidency (2023 Q4)']\n",
      "Preparing to Download:['2023 Israel–Hamas war', '2023 Hamas attack on Israel', 'Joe Biden', 'Timeline of the Joe Biden presidency (2023 Q4)']\n",
      "PageError: The page titled 'Joe Biden' does not exist on Wikipedia.\n",
      "Finished downloading pages\n",
      "['2023 Israel–Hamas war', '2023 Hamas attack on Israel', 'Joe Biden', 'Timeline of the Joe Biden presidency (2023 Q4)'] have been indexed.\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"search_and_index_wikipedia\" *****\u001b[0m\n",
      "['2023 Israel–Hamas war', '2023 Hamas attack on Israel', 'Joe Biden', 'Timeline of the Joe Biden presidency (2023 Q4)']\n",
      "\u001b[32m***********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: query_wiki_index *****\u001b[0m\n",
      "Arguments: \n",
      "{\"hops\":[\"Israel 7th October 2023\",\"Joe Biden response October 2023\"]}\n",
      "\u001b[32m*****************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION query_wiki_index...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"query_wiki_index\" *****\u001b[0m\n",
      "{'4a93e0cc-6b68-46d4-99c3-362f2c74221e': {'texts': ['A series of coordinated attacks, conducted by the Palestinian Islamist militant group Hamas, from the Gaza Strip onto bordering areas in Israel, commenced on Saturday 7 October 2023, a Sabbath day and date of several Jewish holidays. The attacks initiated the 2023 Israel–Hamas war, almost exactly fifty years after the Yom Kippur War began on 6 October 1973. Hamas and other Palestinian armed groups named the attacks Operation Al-Aqsa Flood (or Deluge; Arabic: عملية طوفان الأقصى,'], 'sources': ['https://en.wikipedia.org/wiki/2023_Hamas_attack_on_Israel']}, '9327f7d7-052c-4d1f-b13b-013d540b63a2': {'texts': ['An amendment calling for condemnation of the 7 October \"terrorist attacks\" and immediate release of hostages was rejected.\\n\\n\\n=== Ambassador recalls ===\\nOn the afternoon of Israel\\'s October 31 airstrike on the Jabalia refugee camp, Bolivia severed all diplomatic ties with Israel, followed by a series of ambassador recalls by Chile and Colombia hours later, Jordan on November 1, Bahrain on November 2, Honduras on November 3, Turkey on November 4, Chad on November 5, and South Africa on November 6.'], 'sources': ['https://en.wikipedia.org/wiki/2023_Israel%E2%80%93Hamas_war']}, '3dd6ad55-4c86-411e-963a-35fb312bf353': {'texts': [\"==== Further attacks on October 7 ====\\nStarting at 6.30 a.m. on the same morning, a massacre unfolded at an outdoor music festival near Re'im, resulting in at least 270 dead, and many others missing. Witnesses recounted militants on motorcycles opening fire on fleeing participants, who were already dispersing due to rocket fire that had wounded some attendees; some were also taken hostage.\"], 'sources': ['https://en.wikipedia.org/wiki/2023_Hamas_attack_on_Israel']}, 'e2fd1f14-6652-464a-94c9-683acd820a8b': {'texts': ['The Journal also reported that at a meeting in Beirut on 2 October, five days before the attack, Iranian security officials \"gave the green light\" for the attack. US officials pushed back against the Journal\\'s reporting, stating that its intelligence did not show a direct link between the attack and Iranian officials, while pointing out that Iran had supported Hamas for a long time.In early September 2023, Israel decided a ban of exports of commercial goods from Gaza for several days due to attempts to smuggle explosives, the Palestinians said that the ban affected thousands of families.'], 'sources': ['https://en.wikipedia.org/wiki/2023_Hamas_attack_on_Israel']}, 'c275fec4-adcb-492d-b362-e9e74e12f4d7': {'texts': ['He added that \"whoever starts a war against Israel must lose territory.\"On 15 October, Israeli ambassador to the US Michael Herzog said Israel was \"in the process of establishing … a big humanitarian zone in the southern part of Gaza, with the UN\" able to host hundreds of thousands of Gazans.On 16 October, seven paramedics were killed in an Israeli airstrike on the headquarters of Civil Defense in Gaza City.A spokesperson for Hamas said they are willing to release international hostages \"the moment the conditions on the ground allow\".On 17 October, Israel bombed areas of southern Gaza.'], 'sources': ['https://en.wikipedia.org/wiki/2023_Israel%E2%80%93Hamas_war']}, 'f8266fee-be28-4904-b266-29cace325293': {'texts': [\"Joe Biden, a Democrat from Delaware, was elected President of the United States on November 3, 2020. He was inaugurated on January 20, 2021, as the nation's 46th president. The following articles cover the timeline of Joe Biden, and the time leading up to it:\\n\\n\\n== See also ==\\nTimeline of the Donald Trump presidency, for his predecessor\"], 'sources': ['https://en.wikipedia.org/wiki/Timeline_of_the_Joe_Biden_presidency']}, '0f8b983e-9fb8-489c-9414-4bb2d3e31f83': {'texts': ['On 30 October, the German government called on Israel to protect Palestinians in the West Bank. On 31 October, EU chief diplomat Josep Borrell \"firmly condemned\" settler attacks in the West Bank. Linda Thomas-Greenfield stated the United States was \"deeply concerned,\" and condemned the killings of Palestinians in the West Bank.\\n\\n\\n==== Death toll ====\\nOn 25 October, US President Joe Biden stated he had \"no confidence\" in the death totals reported by the Gaza Health Ministry.'], 'sources': ['https://en.wikipedia.org/wiki/2023_Israel%E2%80%93Hamas_war']}, '6b905fae-c537-4bb0-8ee6-20f6986610e7': {'texts': ['==== Visits by foreign leaders ====\\n\\nOn 17 October, German Chancellor Olaf Scholz visited Israel to express solidarity with the country. On his departure from Ben-Gurion airport, he was evacuated to a shelter after a rocket alarm went off.On 18 October, US President Joe Biden arrived in Israel and was received at Ben-Gurion airport by Israeli President Isaac Herzog and Prime Minister Netanyahu.'], 'sources': ['https://en.wikipedia.org/wiki/2023_Israel%E2%80%93Hamas_war']}, '8904e1ed-cc62-4bed-9eb7-a3854325c5bb': {'texts': ['Later the same day, US president Joe Biden announced Egypt agreed to allow 20 trucks with aid to enter Gaza by 20 October. More than 100 trucks of aid were waiting at the Rafah crossing to enter into Gaza. In a statement, Human Rights Watch stated that without electricity or fuel, however, the provided aid would fail \"meeting the needs of Gaza\\'s population\". On 19 October, US Special Envo y David M. Satterfield stated the US wanted \"sustained\" aid into Gaza.'], 'sources': ['https://en.wikipedia.org/wiki/2023_Israel%E2%80%93Hamas_war']}, '1a51bacd-693a-44cc-ae8d-cd45efbaab22': {'texts': ['President Joe Biden promised \"rock-solid and unwavering\" support to Israel and called Hamas\\'s attack \"unadulterated evil\", comparing the group to ISIS. To replenish Israel\\'s stockpiles, the U.S. said it would send Iron Dome missiles, small bombs, and JDAM conversion kits, in addition to fulfilling previous contracts to deliver F-35 fighter jets, CH-53 helicopters, and KC-46 air refueling tankers.'], 'sources': ['https://en.wikipedia.org/wiki/2023_Israel%E2%80%93Hamas_war']}}\n",
      "\u001b[32m*************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mreporter\u001b[0m (to chat_manager):\n",
      "\n",
      "On October 7, 2023, a series of coordinated attacks by the Palestinian Islamist militant group Hamas were launched from the Gaza Strip onto bordering areas in Israel, marking the beginning of the 2023 Israel–Hamas war. This conflict started almost fifty years after the Yom Kippur War, which began on October 6, 1973. Hamas and other Palestinian armed groups referred to these attacks as Operation Al-Aqsa Flood. On that same morning, a massacre occurred at an outdoor music festival near Re'im, with at least 270 people killed and many others missing or taken hostage as militants on motorcycles opened fire on the attendees who were already trying to flee due to rocket fire [source](https://en.wikipedia.org/wiki/2023_Hamas_attack_on_Israel).\n",
      "\n",
      "In response to the violence and the initiation of the war, US President Joe Biden expressed \"rock-solid and unwavering\" support for Israel and condemned the Hamas attacks as \"unadulterated evil,\" likening the group to ISIS. In support of Israel, the United States announced it would send Iron Dome missiles, small bombs, and JDAM conversion kits, as well as fulfilling previous contracts to deliver F-35 fighter jets, CH-53 helicopters, and KC-46 air refueling tankers to replenish Israel's stockpiles [source](https://en.wikipedia.org/wiki/2023_Israel%E2%80%93Hamas_war).\n",
      "\n",
      "PLEASE REVIEW\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mmoderator\u001b[0m (to chat_manager):\n",
      "\n",
      "The answer is approved.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mreporter\u001b[0m (to chat_manager):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import autogen \n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=5,\n",
    "    system_message='''You should start the workflow by consulting the assistant, then the reporter and finally the moderator. \n",
    "    If the assistant does not use both the `search_and_index_wikipedia` and the `query_wiki_index`, you must request that it does.'''\n",
    "    \n",
    ")\n",
    "\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    system_message='''\n",
    "    As the Information Gatherer, you must start by using the `search_and_index_wikipedia` function to gather relevant data about the user's query. Follow these steps:\n",
    "\n",
    "    1. Upon receiving a query, immediately invoke the `search_and_index_wikipedia` function to find and index Wikipedia pages related to the query. Do not proceed without completing this step.\n",
    "    2. After successfully indexing, utilize the `query_wiki_index` to extract detailed information from the indexed content.\n",
    "    3. Present the indexed information and detailed findings to the Reporter, ensuring they have a comprehensive dataset to draft a response.\n",
    "    4. Conclude your part with \"INFORMATION GATHERING COMPLETE\" to signal that you have finished collecting data and it is now ready for the Reporter to use in formulating the answer.\n",
    "\n",
    "    Remember, you are responsible for information collection and indexing only. The Reporter will rely on the accuracy and completeness of your findings to generate the final answer.\n",
    "\n",
    "    ''',\n",
    "    llm_config=llm_config,\n",
    "    # human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "reporter = autogen.AssistantAgent(\n",
    "    name=\"reporter\",\n",
    "    system_message='''\n",
    "    As the Reporter, you are responsible for formulating an answer to the user's query using the information provided by the Information Gatherer.\n",
    "\n",
    "    1. Wait for the Information Gatherer to complete their task and present you with the indexed information.\n",
    "    2. Using the gathered data, create a comprehensive and precise response that adheres to the criteria of precision, depth, clarity, and proper citation.\n",
    "    3. Present your draft answer followed by \"PLEASE REVIEW\" for the Moderator to assess.\n",
    "\n",
    "    If the Moderator approves your answer, conclude with \"TERMINATE\" to signal the end of the interaction.\n",
    "\n",
    "    If the Moderator rejects your answer:\n",
    "    - Review their feedback.\n",
    "    - Make necessary amendments.\n",
    "    - Resubmit the revised answer with \"PLEASE REVIEW.\"\n",
    "\n",
    "    Ensure that your response is fully informed by the data provided and meets the established criteria.\n",
    "\n",
    "    criteria are as follows:\n",
    "     A. Precision: Directly address the user's question.\n",
    "     B. Depth: Provide comprehensive information using indexed content.\n",
    "     C. Citing: Include clear references from the indexed content AND the Wikipedia link source as a citation.\n",
    "     D. Clarity: Present information logically and coherently.\n",
    "\n",
    "    ''',\n",
    "    llm_config=llm_config_no_tools,\n",
    "    \n",
    "    # human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "moderator = autogen.AssistantAgent(\n",
    "    name=\"moderator\",\n",
    "    system_message='''\n",
    "\n",
    "    As the Moderator, your task is to review the Reporter's answers to ensure they meet the required criteria:\n",
    "\n",
    "    - Assess the Reporter's answers after the \"PLEASE REVIEW\" prompt for alignment with the following criteria:\n",
    "     A. Precision: Directly addressed the user's question.\n",
    "     B. Depth: Provided comprehensive information using indexed content.\n",
    "     C. Citing: Clear references from the indexed content AND the Wikipedia link source as a citation.\n",
    "     D. Clarity: information presented logically and coherently.\n",
    "    - Approve the answer by stating \"The answer is approved\" if it meets the criteria.\n",
    "    - If the answer falls short, specify which criteria were not met and instruct the Reporter to revise the answer accordingly. Do not generate new content or answers yourself.\n",
    "\n",
    "    Your role is crucial in ensuring that the final answer provided to the user is factually correct and meets all specified quality standards.\n",
    "\n",
    "    ''',\n",
    "    llm_config=llm_config_no_tools,\n",
    "    # human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "user_proxy.register_function(\n",
    "    function_map={\n",
    "        \"search_and_index_wikipedia\": search_and_index_wikipedia,\n",
    "        \"query_wiki_index\":query_wiki_index,\n",
    "        # \"generate_response\":generate_response\n",
    "    }\n",
    ")\n",
    "\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, assistant, reporter, moderator], messages=[], max_round=20)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n",
    "user_proxy.initiate_chat(\n",
    "    manager, \n",
    "    message='''What happened in Israel on the 7th October 2023 and what was Biden's response?'''\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
