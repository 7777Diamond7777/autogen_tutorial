{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Gen Tutorial\n",
    "Note book written by John Adeojo\n",
    "Founder, and Chief Data Scientist at [Data-centric Solutions](https://www.data-centric-solutions.com/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "import yaml\n",
    "import openai \n",
    "import os\n",
    "\n",
    "script_dir = \"C:/Users/johna/OneDrive/Documents/api_keys/\"\n",
    "index_path = \"G:/My Drive/Data-Centric Solutions/07. Blog Posts/AutoGen/autogen_tutorial/indexes/\"\n",
    "configurations_path = \"G:/My Drive/Data-Centric Solutions/07. Blog Posts/AutoGen/autogen_tutorial/\"\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file=\"configurations.json\",\n",
    "    file_location=configurations_path,\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-3.5-turbo-16k\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "def get_apikey(script_dir=script_dir):\n",
    "    \"\"\"\n",
    "    Reads API key from a configuration file.\n",
    "\n",
    "    This function opens a configuration file named \"apikeys.yml\", reads the API key for OpenAI\n",
    "\n",
    "    Returns:\n",
    "    api_key (str): The OpenAI API key.\n",
    "    \"\"\"\n",
    "    # Update the script_dir path to point to the correct location in your Google Drive\n",
    "    script_dir = script_dir\n",
    "    file_path = os.path.join(script_dir, \"apikeys.yml\")\n",
    "\n",
    "    with open(file_path, 'r') as yamlfile:\n",
    "        loaded_yamlfile = yaml.safe_load(yamlfile)\n",
    "        API_KEY = loaded_yamlfile['openai']['api_key']\n",
    "\n",
    "    return API_KEY\n",
    "\n",
    "# Call the function to get the API key\n",
    "openai.api_key = get_apikey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool 1: Does a query based search for Wikipages\n",
    "from typing import Any, List\n",
    "import wikipedia\n",
    "from llama_index import download_loader, VectorStoreIndex, ServiceContext\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.text_splitter import get_default_text_splitter\n",
    "import openai\n",
    "from pydantic import BaseModel\n",
    "from llama_index.program import OpenAIPydanticProgram\n",
    "from utils import get_apikey\n",
    "from typing import Callable, Dict, Optional, Union, List, Tuple, Any\n",
    "from llama_hub.wikipedia.base import WikipediaReader\n",
    "from llama_index import StorageContext\n",
    "from llama_index import load_index_from_storage\n",
    "import json\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "class WikiPediaPageName(BaseModel):\n",
    "    \"\"\"Data model for a Wikipedia Page.\"\"\"\n",
    "    page: str\n",
    "\n",
    "class WikiPageList(BaseModel):\n",
    "    \"Data model for WikiPageList\"\n",
    "    pages: List[WikiPediaPageName]\n",
    "\n",
    "def wikipage_list(wikipediapages):\n",
    "        openai.api_key = get_apikey()\n",
    "\n",
    "        prompt_template_str = \"\"\"\n",
    "        Given the input {query}, \n",
    "        return a list of Wikipedia page names.\n",
    "        \"\"\"\n",
    "        program = OpenAIPydanticProgram.from_defaults(\n",
    "            output_cls=WikiPageList,\n",
    "            prompt_template_str=prompt_template_str,\n",
    "            verbose=True,\n",
    "            llm=OpenAI(model=\"gpt-3.5-turbo-16k\")\n",
    "            \n",
    "        )\n",
    "        return program(query=wikipediapages)\n",
    "\n",
    "def search_wikipedia(\n",
    "        query: str, lang: str = \"en\", results_limit: int = 5, **load_kwargs: Any\n",
    "    ) -> List[List]:\n",
    "    wikipedia.set_lang(lang)\n",
    "    return wikipedia.search(query, results=results_limit)\n",
    "\n",
    "def create_wikidocs(wikipage_requests):\n",
    "    print(f\"Preparing to Download:{wikipage_requests}\")\n",
    "    WikipediaReader = download_loader(\"WikipediaReader\")\n",
    "    loader = WikipediaReader()\n",
    "    documents = loader.load_data(pages=wikipage_requests)\n",
    "    return documents\n",
    "\n",
    "def save_index(index) -> None:\n",
    "    index.storage_context.persist(index_path)\n",
    "\n",
    "def index_wikipedia_pages(wikipediapages: list):\n",
    "    global index\n",
    "    wikipage_requests = wikipage_list(wikipediapages)\n",
    "    documents = create_wikidocs(wikipage_requests)\n",
    "    text_splits = get_default_text_splitter(chunk_size=150, chunk_overlap=45)\n",
    "    parser = SimpleNodeParser.from_defaults(text_splitter=text_splits)\n",
    "    service_context = ServiceContext.from_defaults(node_parser=parser)\n",
    "    index =  VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "    save_index(index)\n",
    "\n",
    "def load_index(filepath: str):\n",
    "        # rebuild storage context\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=index_path)\n",
    "        # load index\n",
    "        return load_index_from_storage(storage_context)\n",
    "\n",
    "def read_json_file(file_path: str) -> dict:\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def query_vector_db(\n",
    "        search_string: str,\n",
    "        file_path = index_path,\n",
    "        n_results: int = 10\n",
    ") -> None: \n",
    "    index = load_index(filepath=index_path)\n",
    "    query_engine = index.as_query_engine(\n",
    "        response_mode=\"compact\", verbose=True, similarity_top_k=n_results\n",
    "    )\n",
    "    nodes = query_engine.query(search_string).source_nodes\n",
    "    retrieved_context = {\n",
    "        # \"ids\": [],\n",
    "        \"text\": []\n",
    "    }\n",
    "    for node in nodes:\n",
    "        # retrieved_context[\"ids\"].append(node.node.id_)\n",
    "        retrieved_context[\"text\"].append(node.node.text)\n",
    "    \n",
    "    file_path = index_path + \"retrieved_context.json\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(retrieved_context, f)\n",
    "    \n",
    "    return retrieved_context\n",
    "\n",
    "def generate_response(task:str):\n",
    "    openai.api_key = get_apikey()\n",
    "    context = read_json_file(index_path + \"retrieved_context.json\")\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",  \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": task},\n",
    "            {\"role\": \"assistant\", \"content\": f\"Use the information `{context}` to help you respond to the `{task}`\"}\n",
    "        ]\n",
    "    )\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"search_wikipedia\",\n",
    "            \"description\": \"Use this to search for relevant Wikipedia pages\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A query to search and identify relevant Wikipedia pages\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"name\": \"index_wikipedia_pages\",\n",
    "            \"description\": \"Use this to index wikipedia pages\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"wikipediapages\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The output of the search_wikipedia function\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"wikipediapages\"],\n",
    "            },\n",
    "        },\n",
    "\n",
    "        {\n",
    "            \"name\": \"query_vector_db\",\n",
    "            \"description\": \"Useful for retrieving relevant context from the index\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"search_string\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A query for which relevant context is required from the index\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"search_string\"],\n",
    "            },\n",
    "        },\n",
    "\n",
    "        {\n",
    "            \"name\": \"generate_response\",\n",
    "            \"description\": \"Useful to generate a response based on additional context provided by wikipedia search\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"task\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"task\": \"Your understanding of the task\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"task\"],\n",
    "            },\n",
    "        },   \n",
    "    ],\n",
    "    \"config_list\": config_list,\n",
    "    \"request_timeout\": 600,\n",
    "    \"seed\":43\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mwiki_bot\u001b[0m (to chat_manager):\n",
      "\n",
      "What was the first bank to fail in 2023 US banking crisis?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwikisearch_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: search_wikipedia *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"query\": \"2023 US banking crisis\"\n",
      "}\n",
      "\u001b[32m*****************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION search_wikipedia...\u001b[0m\n",
      "\u001b[33mwiki_bot\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"search_wikipedia\" *****\u001b[0m\n",
      "['2023 United States banking crisis', 'List of banking crises', 'Ghana banking crisis', 'Venezuelan banking crisis of 1994', 'Australian banking crisis of 1893']\n",
      "\u001b[32m*************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwikisearch_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: index_wikipedia_pages *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"wikipediapages\": \"2023 United States banking crisis\"\n",
      "}\n",
      "\u001b[32m**********************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION index_wikipedia_pages...\u001b[0m\n",
      "Function call: WikiPageList with args: {\n",
      "  \"pages\": [\n",
      "    {\n",
      "      \"page\": \"2023 United States banking crisis\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Preparing to Download:pages=[WikiPediaPageName(page='2023 United States banking crisis')]\n",
      "\u001b[33mwiki_bot\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"index_wikipedia_pages\" *****\u001b[0m\n",
      "None\n",
      "\u001b[32m******************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwikisearch_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "I couldn't find any specific information about the first bank to fail in the 2023 US banking crisis.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwikisearch_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: search_wikipedia *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"query\": \"List of banking crises\"\n",
      "}\n",
      "\u001b[32m*****************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION search_wikipedia...\u001b[0m\n",
      "\u001b[33mwiki_bot\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"search_wikipedia\" *****\u001b[0m\n",
      "['List of banking crises', 'List of economic crises', 'Bank run', 'List of sovereign debt crises', 'List of stock market crashes and bear markets']\n",
      "\u001b[32m*************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwikisearch_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: index_wikipedia_pages *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"wikipediapages\": \"List of banking crises\"\n",
      "}\n",
      "\u001b[32m**********************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION index_wikipedia_pages...\u001b[0m\n",
      "Function call: WikiPageList with args: {\n",
      "  \"pages\": [\n",
      "    {\n",
      "      \"page\": \"Banking_crisis\"\n",
      "    },\n",
      "    {\n",
      "      \"page\": \"Financial_crisis\"\n",
      "    },\n",
      "    {\n",
      "      \"page\": \"Subprime_mortgage_crisis\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Preparing to Download:pages=[WikiPediaPageName(page='Banking_crisis'), WikiPediaPageName(page='Financial_crisis'), WikiPediaPageName(page='Subprime_mortgage_crisis')]\n",
      "\u001b[33mwiki_bot\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"index_wikipedia_pages\" *****\u001b[0m\n",
      "None\n",
      "\u001b[32m******************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-04 01:11:21] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 14d0594197350eaba379cfe6e5643360 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 14d0594197350eaba379cfe6e5643360 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 14d0594197350eaba379cfe6e5643360 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 01:11:20 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '1196', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179817', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '60ms', 'x-request-id': '14d0594197350eaba379cfe6e5643360', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208fb776ce94173-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "[autogen.oai.completion: 11-04 01:11:32] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a51e68daa0d6d24286b9580610fdb49c in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a51e68daa0d6d24286b9580610fdb49c in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a51e68daa0d6d24286b9580610fdb49c in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 01:11:31 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '714', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179817', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '60ms', 'x-request-id': 'a51e68daa0d6d24286b9580610fdb49c', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208fbbe8ac84173-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "[autogen.oai.completion: 11-04 01:11:43] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID b7317a73a643d712377380b5f3fd53ed in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID b7317a73a643d712377380b5f3fd53ed in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID b7317a73a643d712377380b5f3fd53ed in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 01:11:42 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '767', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179817', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '60ms', 'x-request-id': 'b7317a73a643d712377380b5f3fd53ed', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208fc0339cc4173-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\u001b[33mresponse_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: generate_response *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"task\": \"I couldn't find specific information about the first bank to fail in the 2023 US banking crisis. Please try searching again.\"\n",
      "}\n",
      "\u001b[32m******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION generate_response...\u001b[0m\n",
      "\u001b[33mwiki_bot\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"generate_response\" *****\u001b[0m\n",
      "{\n",
      "  \"id\": \"chatcmpl-8GzUXWtJXMaK8kqQHnwX7YTS0uCgE\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1699060313,\n",
      "  \"model\": \"gpt-3.5-turbo-16k-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"During the 2023 US banking crisis, the first bank to fail was Silicon Valley Bank (SVB). It experienced a bank run after selling its Treasury bond portfolio at a significant loss, which raised concerns among depositors about the bank's liquidity. SVB primarily served technology companies and wealthy individuals with large deposits, but balances exceeding $250,000 were not insured by the Federal Deposit Insurance Corporation (FDIC). This failure occurred over five days in March 2023 and marked the beginning of the crisis, leading to a decline in global bank stock prices and swift regulatory responses to prevent potential contagion.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 1342,\n",
      "    \"completion_tokens\": 121,\n",
      "    \"total_tokens\": 1463\n",
      "  }\n",
      "}\n",
      "\u001b[32m**************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mresponse_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "During the 2023 US banking crisis, the first bank to fail was Silicon Valley Bank (SVB). It experienced a bank run after selling its Treasury bond portfolio at a significant loss, which raised concerns among depositors about the bank's liquidity. SVB primarily served technology companies and wealthy individuals with large deposits, but balances exceeding $250,000 were not insured by the Federal Deposit Insurance Corporation (FDIC). This failure occurred over five days in March 2023 and marked the beginning of the crisis, leading to a decline in global bank stock prices and swift regulatory responses to prevent potential contagion.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwiki_bot\u001b[0m (to chat_manager):\n",
      "\n",
      "Thank you for providing the information. According to your response, during the 2023 US banking crisis, the first bank to fail was Silicon Valley Bank (SVB). It experienced a bank run after selling its Treasury bond portfolio at a significant loss, which raised concerns among depositors about the bank's liquidity. SVB primarily served technology companies and wealthy individuals with large deposits, but balances exceeding $250,000 were not insured by the Federal Deposit Insurance Corporation (FDIC). This failure occurred over five days in March 2023 and marked the beginning of the crisis, leading to a decline in global bank stock prices and swift regulatory responses to prevent potential contagion.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwikisearch_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "You're welcome! I'm glad I could provide you with the information about the first bank to fail in the 2023 US banking crisis. If you have any more questions, feel free to ask!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-04 01:12:11] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 9e9d1f11d11232efbad49fb590ec9a34 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 9e9d1f11d11232efbad49fb590ec9a34 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 9e9d1f11d11232efbad49fb590ec9a34 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 01:12:10 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '1185', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179169', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '276ms', 'x-request-id': '9e9d1f11d11232efbad49fb590ec9a34', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208fcb31efa4173-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\u001b[33mwiki_index_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "Thank you for your assistance! If I have any more questions or need further information, I'll be sure to reach out. Have a great day!\n",
      "\u001b[32m***** Suggested function Call: index_wikipedia_pages *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"wikipediapages\": \"2023 United States banking crisis\"\n",
      "}\n",
      "\u001b[32m**********************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION index_wikipedia_pages...\u001b[0m\n",
      "Function call: WikiPageList with args: {\n",
      "  \"pages\": [\n",
      "    {\n",
      "      \"page\": \"2023 United States banking crisis\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Preparing to Download:pages=[WikiPediaPageName(page='2023 United States banking crisis')]\n",
      "\u001b[33mwiki_bot\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"index_wikipedia_pages\" *****\u001b[0m\n",
      "None\n",
      "\u001b[32m******************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwikisearch_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: search_wikipedia *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"query\": \"2023 US banking crisis\"\n",
      "}\n",
      "\u001b[32m*****************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION search_wikipedia...\u001b[0m\n",
      "\u001b[33mwiki_bot\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"search_wikipedia\" *****\u001b[0m\n",
      "['2023 United States banking crisis', 'List of banking crises', 'Ghana banking crisis', 'Venezuelan banking crisis of 1994', 'Acquisition of Credit Suisse by UBS']\n",
      "\u001b[32m*************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwikisearch_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: index_wikipedia_pages *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"wikipediapages\": \"2023 United States banking crisis\"\n",
      "}\n",
      "\u001b[32m**********************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import autogen \n",
    "wiki_bot = autogen.UserProxyAgent(\n",
    "    name=\"wiki_bot\",\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    system_message= '''Your job is to use agents to respond to queries.\n",
    "    You will give a final response once you are satisfied with the answer''',\n",
    "    llm_config=llm_config,\n",
    "    \n",
    ")\n",
    "\n",
    "wikisearch_agent = autogen.AssistantAgent(\n",
    "    name=\"wikisearch_agent\",\n",
    "    system_message='''Your job is to search for the titles of relevant Wikipedia pages.\n",
    "    Reply `TERMINATE` in the end when everything is done.''',\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "wiki_index_agent = autogen.AssistantAgent(\n",
    "    name=\"wiki_index_agent\",\n",
    "    system_message='''Your job is to index the relevant wikipedia pages from the titles provided by wikisearch_agent.\n",
    "    Reply `TERMINATE` in the end when everything is done.''',\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "retrieve_agent = autogen.AssistantAgent(\n",
    "    name=\"retrieve_agent\",\n",
    "    system_message='''Your job is to retrieve relevant information from the index.\n",
    "    Reply `TERMINATE` in the end when everything is done.''',\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "response_agent = autogen.AssistantAgent(\n",
    "    name=\"response_agent\",\n",
    "    system_message='''Your job is to generate a response to the task based using the generate_response tool.\n",
    "    Reply `TERMINATE` in the end when everything is done.''',\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "wiki_bot.register_function(\n",
    "    function_map={\n",
    "        \"search_wikipedia\": search_wikipedia,\n",
    "        \"index_wikipedia_pages\":index_wikipedia_pages,\n",
    "        \"query_vector_db\":query_vector_db,\n",
    "        \"generate_response\":generate_response\n",
    "    }\n",
    ")\n",
    "\n",
    "groupchat = autogen.GroupChat(agents=[wiki_bot, wikisearch_agent, wiki_index_agent, retrieve_agent, response_agent], messages=[], max_round=20)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n",
    "wiki_bot.initiate_chat(manager, message=\"What was the first bank to fail in 2023 US banking crisis?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
