{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Gen Tutorial\n",
    "Note book written by John Adeojo\n",
    "Founder, and Chief Data Scientist at [Data-centric Solutions](https://www.data-centric-solutions.com/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import openai\n",
    "\n",
    "script_dir = \"C:/Users/johna/OneDrive/Documents/api_keys/\"\n",
    "\n",
    "# Mount Google Drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "def get_apikey(script_dir=script_dir):\n",
    "    \"\"\"\n",
    "    Reads API key from a configuration file.\n",
    "\n",
    "    This function opens a configuration file named \"apikeys.yml\", reads the API key for OpenAI\n",
    "\n",
    "    Returns:\n",
    "    api_key (str): The OpenAI API key.\n",
    "    \"\"\"\n",
    "    # Update the script_dir path to point to the correct location in your Google Drive\n",
    "    script_dir = script_dir\n",
    "    file_path = os.path.join(script_dir, \"apikeys.yml\")\n",
    "\n",
    "    with open(file_path, 'r') as yamlfile:\n",
    "        loaded_yamlfile = yaml.safe_load(yamlfile)\n",
    "        API_KEY = loaded_yamlfile['openai']['api_key']\n",
    "\n",
    "    return API_KEY\n",
    "\n",
    "# Call the function to get the API key\n",
    "openai.api_key = get_apikey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen \n",
    "\n",
    "index_path = \"G:/My Drive/Data-Centric Solutions/07. Blog Posts/AutoGen/autogen_tutorial/indexes/\"\n",
    "configurations_path = \"G:/My Drive/Data-Centric Solutions/07. Blog Posts/AutoGen/autogen_tutorial/\"\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file=\"configurations.json\",\n",
    "    file_location=configurations_path,\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-3.5-tubro-16k\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool 1: Does a query based search for Wikipages\n",
    "from typing import Any, List\n",
    "import wikipedia\n",
    "from llama_index import download_loader, VectorStoreIndex, ServiceContext\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.text_splitter import get_default_text_splitter\n",
    "import openai\n",
    "from pydantic import BaseModel\n",
    "from llama_index.program import OpenAIPydanticProgram\n",
    "from utils import get_apikey\n",
    "from typing import Callable, Dict, Optional, Union, List, Tuple, Any\n",
    "from llama_hub.wikipedia.base import WikipediaReader\n",
    "from llama_index import StorageContext\n",
    "from llama_index import load_index_from_storage\n",
    "import json\n",
    "from autogen import oai\n",
    "\n",
    "class WikiPediaPageName(BaseModel):\n",
    "    \"\"\"Data model for a Wikipedia Page.\"\"\"\n",
    "    page: str\n",
    "\n",
    "class WikiPageList(BaseModel):\n",
    "    \"Data model for WikiPageList\"\n",
    "    pages: List[WikiPediaPageName]\n",
    "\n",
    "def wikipage_list(wikipediapages):\n",
    "        openai.api_key = get_apikey()\n",
    "\n",
    "        prompt_template_str = \"\"\"\n",
    "        Given the input {query}, \n",
    "        return a list of Wikipedia page names.\n",
    "        \"\"\"\n",
    "        program = OpenAIPydanticProgram.from_defaults(\n",
    "            output_cls=WikiPageList,\n",
    "            prompt_template_str=prompt_template_str,\n",
    "            verbose=True\n",
    "        )\n",
    "        return program(query=wikipediapages)\n",
    "\n",
    "def search_wikipedia(\n",
    "        query: str, lang: str = \"en\", results_limit: int = 5, **load_kwargs: Any\n",
    "    ) -> List[List]:\n",
    "    wikipedia.set_lang(lang)\n",
    "    return wikipedia.search(query, results=results_limit)\n",
    "\n",
    "def create_wikidocs(wikipage_requests):\n",
    "    print(f\"Preparing to Download:{wikipage_requests}\")\n",
    "    WikipediaReader = download_loader(\"WikipediaReader\")\n",
    "    loader = WikipediaReader()\n",
    "    documents = loader.load_data(pages=wikipage_requests)\n",
    "    return documents\n",
    "\n",
    "def save_index(index) -> None:\n",
    "    # index.set_index_id(\"vector_index\")\n",
    "    index.storage_context.persist(index_path)\n",
    "\n",
    "def index_wikipedia_pages(wikipediapages: list):  # Added type hint\n",
    "    global index\n",
    "    wikipage_requests = wikipage_list(wikipediapages)\n",
    "    documents = create_wikidocs(wikipage_requests)\n",
    "    text_splits = get_default_text_splitter(chunk_size=150, chunk_overlap=45)\n",
    "    parser = SimpleNodeParser.from_defaults(text_splitter=text_splits)\n",
    "    service_context = ServiceContext.from_defaults(node_parser=parser)\n",
    "    index =  VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "    save_index(index)\n",
    "\n",
    "\n",
    "def load_index(filepath: str):\n",
    "        # rebuild storage context\n",
    "        # storage_context = StorageContext.from_defaults(persist_dir=\"indexes\")\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=index_path)\n",
    "        # load index\n",
    "        return load_index_from_storage(storage_context)\n",
    "\n",
    "def read_json_file(file_path: str) -> dict:\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def query_vector_db(\n",
    "        search_string: str,\n",
    "        file_path = index_path,\n",
    "        n_results: int = 10\n",
    "        # **kwargs,\n",
    ") -> None:  # Updated return type to None as the function now writes to a file\n",
    "    index = load_index(filepath=index_path)\n",
    "    query_engine = index.as_query_engine(\n",
    "        response_mode=\"compact\", verbose=True, similarity_top_k=n_results\n",
    "    )\n",
    "    nodes = query_engine.query(search_string).source_nodes\n",
    "    retrieved_context = {\n",
    "        # \"ids\": [],\n",
    "        \"text\": []\n",
    "    }\n",
    "    for node in nodes:\n",
    "        # retrieved_context[\"ids\"].append(node.node.id_)\n",
    "        retrieved_context[\"text\"].append(node.node.text)\n",
    "    \n",
    "    file_path = index_path + \"retrieved_context.json\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(retrieved_context, f)\n",
    "    \n",
    "    return retrieved_context\n",
    "\n",
    "# def generate_response(task:str, config_list=config_list):\n",
    "#      context = read_json_file(index_path + \"retrieved_context.json\")\n",
    "#      response = oai.Completion.create(\n",
    "#           config_list=config_list,\n",
    "#           prompt=f\"Use `{context}` to help you respond to the `{task}`\"\n",
    "#      )\n",
    "#      return response\n",
    "\n",
    "def generate_response(task:str):\n",
    "    openai.api_key = get_apikey()\n",
    "    context = read_json_file(index_path + \"retrieved_context.json\")\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",  \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": task},\n",
    "            {\"role\": \"assistant\", \"content\": f\"Use the information `{context}` to help you respond to the `{task}`\"}\n",
    "        ]\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "# # Call the function\n",
    "# def query_vector_db(\n",
    "#         n_results: int = 20,\n",
    "#         search_string: str = \"\",\n",
    "#         # **kwargs,\n",
    "# ) -> Dict[str, Union[List[str], List[List[str]]]]:\n",
    "#     openai.api_key = get_apikey()\n",
    "#     index = load_index(filepath=index_path)\n",
    "#     query_engine = index.as_query_engine(\n",
    "#         response_mode=\"compact\", verbose=True, similarity_top_k=n_results\n",
    "#     )\n",
    "#     nodes = query_engine.query(search_string).source_nodes\n",
    "#     results = {\n",
    "#         \"ids\": [],\n",
    "#         \"text\": []\n",
    "#     }\n",
    "#     for node in nodes:\n",
    "#         results[\"ids\"].append(node.node.id_)\n",
    "#         results[\"text\"].append(node.node.text)\n",
    "#     return results\n",
    "\n",
    "# def retrieve_docs(problem: str, n_results: int = 20, search_string: str = \"\", **kwargs):\n",
    "#     results = query_vector_db(problem, n_results, search_string)\n",
    "#     return results\n",
    "#     print(\"doc_ids: \", results[\"ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"search_wikipedia\",\n",
    "            \"description\": \"Use this to search for relevant Wikipedia pages\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A query to search and identify relevant Wikipedia pages\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"name\": \"index_wikipedia_pages\",\n",
    "            \"description\": \"Use this to index wikipedia pages\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"wikipediapages\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The output of the search_wikipedia function\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"wikipediapages\"],\n",
    "            },\n",
    "        },\n",
    "\n",
    "        {\n",
    "            \"name\": \"query_vector_db\",\n",
    "            \"description\": \"Useful for retrieving relevant context from the index\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"search_string\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A query for which relevant context is required from the index\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"search_string\"],\n",
    "            },\n",
    "        },\n",
    "\n",
    "        {\n",
    "            \"name\": \"generate_response\",\n",
    "            \"description\": \"Useful to generate a response based on additional context provided by wikipedia search\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"task\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"task\": \"Your understanding of the task\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"task\"],\n",
    "            },\n",
    "        },\n",
    "        \n",
    "    ],\n",
    "    \"config_list\": config_list,\n",
    "    \"request_timeout\": 120,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "# import openai\n",
    "# from utils import get_apikey\n",
    "# from llama_index import StorageContext\n",
    "# from llama_index import load_index_from_storage\n",
    "\n",
    "\n",
    "# class WikipediaRetrieverUserProxyAgent(RetrieveUserProxyAgent):\n",
    "#     def __init__(self, index_path=index_path, **kwargs):\n",
    "#         super().__init__(**kwargs)  # Fixed superclass constructor call\n",
    "#         # openai.api_key = get_apikey()\n",
    "#         self.index_path = index_path\n",
    "\n",
    "#     @staticmethod\n",
    "#     def load_index(filepath: str):\n",
    "#         # rebuild storage context\n",
    "#         storage_context = StorageContext.from_defaults(persist_dir=\"indexes\")\n",
    "#         # load index\n",
    "#         return load_index_from_storage(storage_context, index_id=\"vector_index\")\n",
    "    \n",
    "#     def query_vector_db(\n",
    "#             self,\n",
    "#             n_results: int = 20,\n",
    "#             search_string: str = \"\",\n",
    "#             **kwargs,\n",
    "#     ) -> Dict[str, Union[List[str], List[List[str]]]]:\n",
    "#         index = self.load_index(self.index_path)\n",
    "#         query_engine = index.as_query_engine(\n",
    "#             response_mode=\"compact\", verbose=True, similarity_top_k=n_results\n",
    "#         )\n",
    "#         nodes = query_engine.query(search_string).source_nodes\n",
    "#         results = {\n",
    "#             \"ids\": [],\n",
    "#             \"text\": []\n",
    "#         }\n",
    "#         for node in nodes:\n",
    "#             results[\"ids\"].append(node.node.id_)\n",
    "#             results[\"text\"].append(node.node.text)\n",
    "#         return results \n",
    "\n",
    "#     def retrieve_docs(self, problem: str, n_results: int = 20, search_string: str = \"\", **kwargs):\n",
    "#         results = self.query_vector_db(problem, n_results, search_string)\n",
    "#         self._results = results\n",
    "#         print(\"doc_ids: \", results[\"ids\"])\n",
    "\n",
    "# # class WikipediaRetrieverUserProxyAgent(RetrieveUserProxyAgent):\n",
    "# #     def __init__(self, index, **kwargs):\n",
    "# #         super().__init__(**kwargs)  # Fixed superclass constructor call\n",
    "# #         # Set the OpenAI API key when the class is instantiated\n",
    "# #         openai.api_key = get_apikey()\n",
    "# #         self.index=index\n",
    "\n",
    "# #     def query_vector_db(\n",
    "# #             self,\n",
    "# #             n_results: int = 20,\n",
    "# #             search_string: str = \"\",\n",
    "# #             **kwargs,\n",
    "# #     ) -> Dict[str, Union[List[str], List[List[str]]]]:\n",
    "# #         query_engine = self.index.as_query_engine(\n",
    "# #             response_mode=\"compact\", verbose=True, similarity_top_k=n_results\n",
    "# #         )\n",
    "# #         nodes = query_engine.query(search_string)\n",
    "# #         results = {\n",
    "# #             \"ids\": [],\n",
    "# #             \"text\": []\n",
    "# #         }\n",
    "# #         for node in nodes:\n",
    "# #             results[\"ids\"].append(node.node.id_)\n",
    "# #             results[\"text\"].append(node.node.text) \n",
    "    \n",
    "# #     def retrieve_docs(self, problem: str, n_results: int = 20, search_string: str = \"\", **kwargs):\n",
    "# #         results = self.query_vector_db(problem, n_results, search_string)\n",
    "# #         self._results = results\n",
    "# #         print(\"doc_ids: \", results[\"ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Which bank was the first to fail in the 2023 banking crisis?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-03 23:03:13] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "[autogen.oai.completion: 11-03 23:03:13] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33mwikisearch_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: search_wikipedia *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"query\": \"first bank to fail in 2023 banking crisis\"\n",
      "}\n",
      "\u001b[32m*****************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION search_wikipedia...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"search_wikipedia\" *****\u001b[0m\n",
      "['2023 United States banking crisis', 'Too big to fail', 'Venezuelan banking crisis of 1994', 'Bank run', 'List of banking crises']\n",
      "\u001b[32m*************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-03 23:03:14] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "[autogen.oai.completion: 11-03 23:03:14] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33mwiki_index_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: index_wikipedia_pages *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"wikipediapages\": \"2023 United States banking crisis\"\n",
      "}\n",
      "\u001b[32m**********************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION index_wikipedia_pages...\u001b[0m\n",
      "Function call: WikiPageList with args: {\n",
      "  \"pages\": [\n",
      "    {\n",
      "      \"page\": \"2023 United States banking crisis\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Preparing to Download:pages=[WikiPediaPageName(page='2023 United States banking crisis')]\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"index_wikipedia_pages\" *****\u001b[0m\n",
      "None\n",
      "\u001b[32m******************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-03 23:03:22] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "[autogen.oai.completion: 11-03 23:03:22] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33mretrieve_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: query_vector_db *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"search_string\": \"first bank to fail in 2023 banking crisis\"\n",
      "}\n",
      "\u001b[32m****************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION query_vector_db...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"query_vector_db\" *****\u001b[0m\n",
      "{'text': ['Also, several banks gained market exposure to cryptocurrency and cryptocurrency-related firms prior to and during the COVID-19 pandemic; the 2020–2022 cryptocurrency bubble popped in late 2022. In this environment, three such banks failed or were shut down by regulators: The first bank to fail, cryptocurrency-focused Silvergate Bank, announced it would wind down on March 8, 2023 due to losses suffered in its loan portfolio. Two days later, upon announcement of an attempt to raise capital, a bank run occurred at Silicon Valley Bank, causing it to collapse and be seized by regulators that day.', \"Over the course of five days in March 2023, three small- to mid-size U.S. banks failed, triggering a sharp decline in global bank stock prices and swift response by regulators to prevent potential global contagion. Silicon Valley Bank (SVB) failed when a bank run was triggered after it sold its Treasury bond portfolio at a large loss, causing depositor concerns about the bank's liquidity. The bonds had lost significant value as market interest rates rose after the bank had shifted its portfolio to longer-maturity bonds. The bank's clientele was primarily technology companies and wealthy individuals holding large deposits, but balances exceeding $250,000 were not insured by the Federal Deposit Insurance Corporation (FDIC).\", \"Large declines in regional bank stocks continued after First Republic's failure.U.S. President Joe Biden made a statement about the first three bank failures on March 13, and asserted that government intervention was not a bailout and that the banking system was stable.The initial bank failures led to speculation on March 13 that the Federal Reserve could pause or halt rate hikes. Beginning on March 13, traders began modifying their strategies in the expectation that fewer hikes than previously expected will occur. Some financial experts suggested that the BTFP, combined with a recent practice of finding buyers who would cover all deposits, may have effectively removed the FDIC's $250,000 deposit insurance limit.\", 'Signature Bank, a bank that frequently did business with cryptocurrency firms, was closed by regulators two days later on March 12, with regulators citing systemic risks. The collapses of First Republic Bank, Silicon Valley Bank and Signature Bank were the second-, third- and fourth-largest bank failures in the history of the United States, respectively, smaller only than the collapse of Washington Mutual during the 2007–2008 financial crisis.In 2019, the Federal Reserve\\'s \"Tailoring rules\" changed, increasing minimum asset threshold from $50 billion to $100 billion and reduced the number of required stress testing scenarios, allowing banks with under $100 billion to have reduced liquidity standards.', 'banks, on top of a $70 billion financing facility provided by JPMorgan Chase & Co. Eleven of the largest U.S. banks participated in the rescue effort, under the direction of Jamie Dimon.On March 19, S&P Global downgraded the credit rating of First Republic Bank further into junk by three notches saying that the private-sector rescue effort \"may not solve the substantial business, liquidity, funding, and profitability challenges that we believe the bank is now likely facing.\" In its quarterly report in April, the bank said that deposits had plunged by more than $100 billion.', \"According to Signature Bank board member Barney Frank, Signature Bank was hit with a multi-billion dollar bank run on Friday, March 10, with depositors expressing concern about cryptocurrency-related risks affecting the bank. Investor confidence in the bank was also badly shaken, and the bank's stock declined by 23% on that Friday—the day on which Silicon Valley bank collapsed—marking the then-largest single-day decline of the Signature Bank's value in its 22-year history.On March 12, 2023, two days after the collapse of Silicon Valley Bank, Signature Bank was closed by regulators from the New York State Department of Financial Services in what is the third-biggest banking collapse in U.S. history.\", \"Shares in other European banks also fell, among them Commerzbank, Austria's Raiffeisen Bank and the French Société Générale. According to the European Commission's Paolo Gentiloni, finance ministers in the Euro zone called on the Commission to close loopholes in Crisis Management and Deposit Insurance (CMDI) provision, starting in the second quarter of 2023.Chinese banks experienced little negative effect. According to Bloomberg News, almost all of the 166 top performers during the market turmoil were in China. The banking crisis in the U.S. and Europe highlighted the relative stability of the Chinese banking system.\", '=== Events ===\\nIntense scrutiny and pressure were applied to other U.S. banks, including FRB. On March 13, its shares fell by 62%. As the bank faced significant liquidity issues, on March 16, it received a $30 billion lifeline in the form of deposits from a number of major U.S. banks, on top of a $70 billion financing facility provided by JPMorgan Chase & Co. Eleven of the largest U.S.', \"These swaps had previously been set up to occur on a weekly cadence.The share price of PacWest had fallen sharply on 3 May after the bank announced that it was 'considering strategic options including a sale'. On 4 May share trading was suspended as the sell-off marked a further 42% loss with other US regional banks, including First Horizon, Metropolitan Bank and Western Alliance, also being affected.In May 2023, FDIC proposed imposing higher fees on an estimated 113 of the largest banks to cover the costs of bailing out uninsured depositors.\\n\\n\\n=== International impact ===\\nBy 19 March, concerns about the banking sector internationally had increased.\", 'It also disclosed it had found \"material weaknesses\" in its financial reporting. Its largest investor, Saudi National Bank, announced on March 15 that it would not provide more support to Credit Suisse. Its share price plunged 25% on the news and UBS stepped in to buy the bank. Axel Lehmann, former chairman of the bank, later sought to blame the American bank failures for triggering Credit Suisse\\'s demise, though other analysts disputed that characterization. The bank had experienced many years of multi-billion dollar losses, scandals, executive turnover and weak business strategy.Late on Sunday the Federal Reserve and several other central banks announced significant USD liquidity measures in order to calm market turmoil.']}\n",
      "\u001b[32m************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-03 23:03:24] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "[autogen.oai.completion: 11-03 23:03:26] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33mresponse_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: generate_response *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"task\": \"Which bank was the first to fail in the 2023 banking crisis?\"\n",
      "}\n",
      "\u001b[32m******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION generate_response...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"generate_response\" *****\u001b[0m\n",
      "{\n",
      "  \"id\": \"chatcmpl-8GxUHVnDZFpl7tLvWMom1wViuRYJs\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1699052609,\n",
      "  \"model\": \"gpt-3.5-turbo-16k-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"The first bank to fail in the 2023 banking crisis was Silvergate Bank, which was a cryptocurrency-focused bank. It announced on March 8, 2023, that it would wind down due to losses suffered in its loan portfolio.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 1363,\n",
      "    \"completion_tokens\": 49,\n",
      "    \"total_tokens\": 1412\n",
      "  }\n",
      "}\n",
      "\u001b[32m**************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-03 23:03:31] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    }
   ],
   "source": [
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=5,\n",
    "    system_message= \"You are the manager that ensures all the agents take neccessary steps to respond to the task.\",\n",
    "    code_execution_config={\"work_dir\": \"coding\"},\n",
    ")\n",
    "\n",
    "wikisearch_agent = autogen.AssistantAgent(\n",
    "    name=\"wikisearch_agent\",\n",
    "    system_message=\"Your job is to search for Wikipedia pages relevant to the task with the search_wikipedia tool.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# wikise_agent = autogen.AssistantAgent(\n",
    "#     name=\"wikisearch_agent\",\n",
    "#     system_message=\"Your job is to search for relevant Wikipedia pages with the search_wikipedia tool.\",\n",
    "#     llm_config=llm_config,\n",
    "# )\n",
    "\n",
    "wiki_index_agent = autogen.AssistantAgent(\n",
    "    name=\"wiki_index_agent\",\n",
    "    system_message=\"Index relevant Wikipedia pages using the index_wikipedia_pages tool as suggested by the wikisearch_agent\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "retrieve_agent = autogen.AssistantAgent(\n",
    "    name=\"retrieve_agent\",\n",
    "    system_message=\"Retrieve relevant from the index information with the query_vector_db tool and communicate it\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "response_agent = autogen.AssistantAgent(\n",
    "    name=\"response_agent\",\n",
    "    system_message=\"Generate a response to the task based using the generate_response tool.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "\n",
    "# retrieve_response_agent = WikipediaRetrieverUserProxyAgent(\n",
    "#     name=\"retrieve_response_agent\",\n",
    "#     system_message=\"Generate response based on context\",\n",
    "#     human_input_mode=\"NEVER\",\n",
    "#     llm_config=llm_config,\n",
    "#     index_path=index_path\n",
    "    \n",
    "# )\n",
    "\n",
    "user_proxy.register_function(\n",
    "    function_map={\n",
    "        \"search_wikipedia\": search_wikipedia,\n",
    "        \"index_wikipedia_pages\":index_wikipedia_pages,\n",
    "        \"query_vector_db\":query_vector_db,\n",
    "        \"generate_response\":generate_response\n",
    "    }\n",
    ")\n",
    "\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, wikisearch_agent, wiki_index_agent, retrieve_agent, response_agent], messages=[], max_round=100)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n",
    "\n",
    "user_proxy.initiate_chat(manager, message=\"Which bank was the first to fail in the 2023 banking crisis?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
