{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Gen Tutorial\n",
    "Note book written by John Adeojo\n",
    "Founder, and Chief Data Scientist at [Data-centric Solutions](https://www.data-centric-solutions.com/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import openai\n",
    "\n",
    "script_dir = \"C:/Users/johna/OneDrive/Documents/api_keys/\"\n",
    "\n",
    "# Mount Google Drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "def get_apikey(script_dir=script_dir):\n",
    "    \"\"\"\n",
    "    Reads API key from a configuration file.\n",
    "\n",
    "    This function opens a configuration file named \"apikeys.yml\", reads the API key for OpenAI\n",
    "\n",
    "    Returns:\n",
    "    api_key (str): The OpenAI API key.\n",
    "    \"\"\"\n",
    "    # Update the script_dir path to point to the correct location in your Google Drive\n",
    "    script_dir = script_dir\n",
    "    file_path = os.path.join(script_dir, \"apikeys.yml\")\n",
    "\n",
    "    with open(file_path, 'r') as yamlfile:\n",
    "        loaded_yamlfile = yaml.safe_load(yamlfile)\n",
    "        API_KEY = loaded_yamlfile['openai']['api_key']\n",
    "\n",
    "    return API_KEY\n",
    "\n",
    "# Call the function to get the API key\n",
    "openai.api_key = get_apikey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen \n",
    "\n",
    "index_path = \"G:/My Drive/Data-Centric Solutions/07. Blog Posts/AutoGen/autogen_tutorial/indexes/\"\n",
    "configurations_path = \"G:/My Drive/Data-Centric Solutions/07. Blog Posts/AutoGen/autogen_tutorial/\"\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file=\"configurations.json\",\n",
    "    file_location=configurations_path,\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-3.5-tubro-16k\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool 1: Does a query based search for Wikipages\n",
    "from typing import Any, List\n",
    "import wikipedia\n",
    "from llama_index import download_loader, VectorStoreIndex, ServiceContext\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.text_splitter import get_default_text_splitter\n",
    "import openai\n",
    "from pydantic import BaseModel\n",
    "from llama_index.program import OpenAIPydanticProgram\n",
    "from utils import get_apikey\n",
    "from typing import Callable, Dict, Optional, Union, List, Tuple, Any\n",
    "from llama_hub.wikipedia.base import WikipediaReader\n",
    "from llama_index import StorageContext\n",
    "from llama_index import load_index_from_storage\n",
    "import json\n",
    "\n",
    "class WikiPediaPageName(BaseModel):\n",
    "    \"\"\"Data model for a Wikipedia Page.\"\"\"\n",
    "    page: str\n",
    "\n",
    "class WikiPageList(BaseModel):\n",
    "    \"Data model for WikiPageList\"\n",
    "    pages: List[WikiPediaPageName]\n",
    "\n",
    "def wikipage_list(wikipediapages):\n",
    "        openai.api_key = get_apikey()\n",
    "\n",
    "        prompt_template_str = \"\"\"\n",
    "        Given the input {query}, \n",
    "        return a list of Wikipedia page names.\n",
    "        \"\"\"\n",
    "        program = OpenAIPydanticProgram.from_defaults(\n",
    "            output_cls=WikiPageList,\n",
    "            prompt_template_str=prompt_template_str,\n",
    "            verbose=True\n",
    "        )\n",
    "        return program(query=wikipediapages)\n",
    "\n",
    "def search_wikipedia(\n",
    "        query: str, lang: str = \"en\", results_limit: int = 5, **load_kwargs: Any\n",
    "    ) -> List[List]:\n",
    "    wikipedia.set_lang(lang)\n",
    "    return wikipedia.search(query, results=results_limit)\n",
    "\n",
    "def create_wikidocs(wikipage_requests):\n",
    "    print(f\"Preparing to Download:{wikipage_requests}\")\n",
    "    WikipediaReader = download_loader(\"WikipediaReader\")\n",
    "    loader = WikipediaReader()\n",
    "    documents = loader.load_data(pages=wikipage_requests)\n",
    "    return documents\n",
    "\n",
    "def save_index(index) -> None:\n",
    "    index.storage_context.persist(index_path)\n",
    "\n",
    "def index_wikipedia_pages(wikipediapages: list):\n",
    "    global index\n",
    "    wikipage_requests = wikipage_list(wikipediapages)\n",
    "    documents = create_wikidocs(wikipage_requests)\n",
    "    text_splits = get_default_text_splitter(chunk_size=150, chunk_overlap=45)\n",
    "    parser = SimpleNodeParser.from_defaults(text_splitter=text_splits)\n",
    "    service_context = ServiceContext.from_defaults(node_parser=parser)\n",
    "    index =  VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "    save_index(index)\n",
    "\n",
    "\n",
    "def load_index(filepath: str):\n",
    "        # rebuild storage context\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=index_path)\n",
    "        # load index\n",
    "        return load_index_from_storage(storage_context)\n",
    "\n",
    "def read_json_file(file_path: str) -> dict:\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def query_vector_db(\n",
    "        search_string: str,\n",
    "        file_path = index_path,\n",
    "        n_results: int = 10\n",
    ") -> None: \n",
    "    index = load_index(filepath=index_path)\n",
    "    query_engine = index.as_query_engine(\n",
    "        response_mode=\"compact\", verbose=True, similarity_top_k=n_results\n",
    "    )\n",
    "    nodes = query_engine.query(search_string).source_nodes\n",
    "    retrieved_context = {\n",
    "        # \"ids\": [],\n",
    "        \"text\": []\n",
    "    }\n",
    "    for node in nodes:\n",
    "        # retrieved_context[\"ids\"].append(node.node.id_)\n",
    "        retrieved_context[\"text\"].append(node.node.text)\n",
    "    \n",
    "    file_path = index_path + \"retrieved_context.json\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(retrieved_context, f)\n",
    "    \n",
    "    return retrieved_context\n",
    "\n",
    "def generate_response(task:str):\n",
    "    openai.api_key = get_apikey()\n",
    "    context = read_json_file(index_path + \"retrieved_context.json\")\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",  \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": task},\n",
    "            {\"role\": \"assistant\", \"content\": f\"Use the information `{context}` to help you respond to the `{task}`\"}\n",
    "        ]\n",
    "    )\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"search_wikipedia\",\n",
    "            \"description\": \"Use this to search for relevant Wikipedia pages\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A query to search and identify relevant Wikipedia pages\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"name\": \"index_wikipedia_pages\",\n",
    "            \"description\": \"Use this to index wikipedia pages\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"wikipediapages\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The output of the search_wikipedia function\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"wikipediapages\"],\n",
    "            },\n",
    "        },\n",
    "\n",
    "        {\n",
    "            \"name\": \"query_vector_db\",\n",
    "            \"description\": \"Useful for retrieving relevant context from the index\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"search_string\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A query for which relevant context is required from the index\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"search_string\"],\n",
    "            },\n",
    "        },\n",
    "\n",
    "        {\n",
    "            \"name\": \"generate_response\",\n",
    "            \"description\": \"Useful to generate a response based on additional context provided by wikipedia search\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"task\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"task\": \"Your understanding of the task\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"task\"],\n",
    "            },\n",
    "        },\n",
    "        \n",
    "    ],\n",
    "    \"config_list\": config_list,\n",
    "    \"request_timeout\": 120,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Which bank was the first to fail in the 2023 banking crisis?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-03 23:12:35] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "[autogen.oai.completion: 11-03 23:12:37] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33mwikisearch_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: search_wikipedia *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"query\": \"first bank to fail in the 2023 banking crisis\"\n",
      "}\n",
      "\u001b[32m*****************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION search_wikipedia...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"search_wikipedia\" *****\u001b[0m\n",
      "['2023 United States banking crisis', 'Too big to fail', 'Venezuelan banking crisis of 1994', 'Bank run', 'List of banking crises']\n",
      "\u001b[32m*************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-03 23:12:41] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "[autogen.oai.completion: 11-03 23:12:45] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33mwikisearch_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: index_wikipedia_pages *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"wikipediapages\": \"2023 United States banking crisis\"\n",
      "}\n",
      "\u001b[32m**********************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION index_wikipedia_pages...\u001b[0m\n",
      "Function call: WikiPageList with args: {\n",
      "  \"pages\": [\n",
      "    {\n",
      "      \"page\": \"2023 United States banking crisis\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Preparing to Download:pages=[WikiPediaPageName(page='2023 United States banking crisis')]\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"index_wikipedia_pages\" *****\u001b[0m\n",
      "None\n",
      "\u001b[32m******************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-03 23:12:57] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "[autogen.oai.completion: 11-03 23:12:59] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "[autogen.oai.completion: 11-03 23:13:03] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 8a7653d07fd5d39e5308086d0979572e in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 8a7653d07fd5d39e5308086d0979572e in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 8a7653d07fd5d39e5308086d0979572e in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Fri, 03 Nov 2023 23:13:02 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-4-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '3621', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '40000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '39914', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '129ms', 'x-request-id': '8a7653d07fd5d39e5308086d0979572e', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '82084e1f0a466373-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\u001b[33mretrieve_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: query_vector_db *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"search_string\": \"first bank to fail in the 2023 banking crisis\"\n",
      "}\n",
      "\u001b[32m****************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION query_vector_db...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"query_vector_db\" *****\u001b[0m\n",
      "{'text': ['Also, several banks gained market exposure to cryptocurrency and cryptocurrency-related firms prior to and during the COVID-19 pandemic; the 2020–2022 cryptocurrency bubble popped in late 2022. In this environment, three such banks failed or were shut down by regulators: The first bank to fail, cryptocurrency-focused Silvergate Bank, announced it would wind down on March 8, 2023 due to losses suffered in its loan portfolio. Two days later, upon announcement of an attempt to raise capital, a bank run occurred at Silicon Valley Bank, causing it to collapse and be seized by regulators that day.', \"Large declines in regional bank stocks continued after First Republic's failure.U.S. President Joe Biden made a statement about the first three bank failures on March 13, and asserted that government intervention was not a bailout and that the banking system was stable.The initial bank failures led to speculation on March 13 that the Federal Reserve could pause or halt rate hikes. Beginning on March 13, traders began modifying their strategies in the expectation that fewer hikes than previously expected will occur. Some financial experts suggested that the BTFP, combined with a recent practice of finding buyers who would cover all deposits, may have effectively removed the FDIC's $250,000 deposit insurance limit.\", \"Over the course of five days in March 2023, three small- to mid-size U.S. banks failed, triggering a sharp decline in global bank stock prices and swift response by regulators to prevent potential global contagion. Silicon Valley Bank (SVB) failed when a bank run was triggered after it sold its Treasury bond portfolio at a large loss, causing depositor concerns about the bank's liquidity. The bonds had lost significant value as market interest rates rose after the bank had shifted its portfolio to longer-maturity bonds. The bank's clientele was primarily technology companies and wealthy individuals holding large deposits, but balances exceeding $250,000 were not insured by the Federal Deposit Insurance Corporation (FDIC).\", 'Signature Bank, a bank that frequently did business with cryptocurrency firms, was closed by regulators two days later on March 12, with regulators citing systemic risks. The collapses of First Republic Bank, Silicon Valley Bank and Signature Bank were the second-, third- and fourth-largest bank failures in the history of the United States, respectively, smaller only than the collapse of Washington Mutual during the 2007–2008 financial crisis.In 2019, the Federal Reserve\\'s \"Tailoring rules\" changed, increasing minimum asset threshold from $50 billion to $100 billion and reduced the number of required stress testing scenarios, allowing banks with under $100 billion to have reduced liquidity standards.', 'banks, on top of a $70 billion financing facility provided by JPMorgan Chase & Co. Eleven of the largest U.S. banks participated in the rescue effort, under the direction of Jamie Dimon.On March 19, S&P Global downgraded the credit rating of First Republic Bank further into junk by three notches saying that the private-sector rescue effort \"may not solve the substantial business, liquidity, funding, and profitability challenges that we believe the bank is now likely facing.\" In its quarterly report in April, the bank said that deposits had plunged by more than $100 billion.', \"According to Signature Bank board member Barney Frank, Signature Bank was hit with a multi-billion dollar bank run on Friday, March 10, with depositors expressing concern about cryptocurrency-related risks affecting the bank. Investor confidence in the bank was also badly shaken, and the bank's stock declined by 23% on that Friday—the day on which Silicon Valley bank collapsed—marking the then-largest single-day decline of the Signature Bank's value in its 22-year history.On March 12, 2023, two days after the collapse of Silicon Valley Bank, Signature Bank was closed by regulators from the New York State Department of Financial Services in what is the third-biggest banking collapse in U.S. history.\", '=== Events ===\\nIntense scrutiny and pressure were applied to other U.S. banks, including FRB. On March 13, its shares fell by 62%. As the bank faced significant liquidity issues, on March 16, it received a $30 billion lifeline in the form of deposits from a number of major U.S. banks, on top of a $70 billion financing facility provided by JPMorgan Chase & Co. Eleven of the largest U.S.', \"Shares in other European banks also fell, among them Commerzbank, Austria's Raiffeisen Bank and the French Société Générale. According to the European Commission's Paolo Gentiloni, finance ministers in the Euro zone called on the Commission to close loopholes in Crisis Management and Deposit Insurance (CMDI) provision, starting in the second quarter of 2023.Chinese banks experienced little negative effect. According to Bloomberg News, almost all of the 166 top performers during the market turmoil were in China. The banking crisis in the U.S. and Europe highlighted the relative stability of the Chinese banking system.\", \"These swaps had previously been set up to occur on a weekly cadence.The share price of PacWest had fallen sharply on 3 May after the bank announced that it was 'considering strategic options including a sale'. On 4 May share trading was suspended as the sell-off marked a further 42% loss with other US regional banks, including First Horizon, Metropolitan Bank and Western Alliance, also being affected.In May 2023, FDIC proposed imposing higher fees on an estimated 113 of the largest banks to cover the costs of bailing out uninsured depositors.\\n\\n\\n=== International impact ===\\nBy 19 March, concerns about the banking sector internationally had increased.\", 'After falling another 42% in after hours trading, the FDIC confirmed its imminent takeover of the bank. In 2023, the cumulative decrease in stock price was 97%. The next day, the FDIC approached various banks, including JPMorgan Chase, PNC and Bank of America, saying they had until April 30 to place bids for First Republic Bank.On the morning of May 1, the California Department of Financial Protection and Innovation announced that FRB had been closed, and its assets were sold to JPMorgan for $10.6 billion.\\n\\n\\n== Aftermath ==\\n\\n\\n=== Federal response ===']}\n",
      "\u001b[32m************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-03 23:13:18] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "[autogen.oai.completion: 11-03 23:13:19] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33mresponse_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: generate_response *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"task\": \"Which bank was the first to fail in the 2023 banking crisis?\"\n",
      "}\n",
      "\u001b[32m******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION generate_response...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"generate_response\" *****\u001b[0m\n",
      "{\n",
      "  \"id\": \"chatcmpl-8Gxdr5T4xAhoyANwAfDvcGBJcq00Q\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1699053203,\n",
      "  \"model\": \"gpt-3.5-turbo-16k-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"The first bank to fail in the 2023 banking crisis was Silvergate Bank, which was a cryptocurrency-focused bank. It announced on March 8, 2023, that it would wind down due to losses suffered in its loan portfolio.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 1356,\n",
      "    \"completion_tokens\": 49,\n",
      "    \"total_tokens\": 1405\n",
      "  }\n",
      "}\n",
      "\u001b[32m**************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-03 23:13:25] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-03 23:13:27] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n"
     ]
    }
   ],
   "source": [
    "import autogen \n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=5,\n",
    "    system_message= \"Your job is to ask the right questions to complete the task\",\n",
    "    code_execution_config={\"work_dir\": \"coding\"},\n",
    ")\n",
    "\n",
    "wikisearch_agent = autogen.AssistantAgent(\n",
    "    name=\"wikisearch_agent\",\n",
    "    system_message=\"Your job is to search for relevant Wikipedia pages.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "wiki_index_agent = autogen.AssistantAgent(\n",
    "    name=\"wiki_index_agent\",\n",
    "    system_message=\"Your job is to index the relevant wikipedia pages from those suggested by wikisearch_agent.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "retrieve_agent = autogen.AssistantAgent(\n",
    "    name=\"retrieve_agent\",\n",
    "    system_message=\"Your job is to retrieve relevant information from the index.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "response_agent = autogen.AssistantAgent(\n",
    "    name=\"response_agent\",\n",
    "    system_message=\"Generate a response to the task based using the generate_response tool.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "user_proxy.register_function(\n",
    "    function_map={\n",
    "        \"search_wikipedia\": search_wikipedia,\n",
    "        \"index_wikipedia_pages\":index_wikipedia_pages,\n",
    "        \"query_vector_db\":query_vector_db,\n",
    "        \"generate_response\":generate_response\n",
    "    }\n",
    ")\n",
    "\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, wikisearch_agent, wiki_index_agent, retrieve_agent, response_agent], messages=[], max_round=100)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n",
    "user_proxy.initiate_chat(manager, message=\"Which bank was the first to fail in the 2023 banking crisis?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
