{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Gen Tutorial\n",
    "Note book written by John Adeojo\n",
    "Founder, and Chief Data Scientist at [Data-centric Solutions](https://www.data-centric-solutions.com/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'model': 'gpt-3.5-turbo-16k', 'api_key': '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'}]\n"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "import yaml\n",
    "import openai \n",
    "import os\n",
    "\n",
    "script_dir = \"C:/Users/johna/OneDrive/Documents/api_keys/\"\n",
    "index_path = \"G:/My Drive/Data-Centric Solutions/07. Blog Posts/AutoGen/autogen_tutorial/indexes/\"\n",
    "configurations_path = \"G:/My Drive/Data-Centric Solutions/07. Blog Posts/AutoGen/autogen_tutorial/\"\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file=\"configurations.json\",\n",
    "    file_location=configurations_path,\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-3.5-turbo-16k\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "print(config_list)\n",
    "\n",
    "def get_apikey(script_dir=script_dir):\n",
    "    \"\"\"\n",
    "    Reads API key from a configuration file.\n",
    "\n",
    "    This function opens a configuration file named \"apikeys.yml\", reads the API key for OpenAI\n",
    "\n",
    "    Returns:\n",
    "    api_key (str): The OpenAI API key.\n",
    "    \"\"\"\n",
    "    # Update the script_dir path to point to the correct location in your Google Drive\n",
    "    script_dir = script_dir\n",
    "    file_path = os.path.join(script_dir, \"apikeys.yml\")\n",
    "\n",
    "    with open(file_path, 'r') as yamlfile:\n",
    "        loaded_yamlfile = yaml.safe_load(yamlfile)\n",
    "        API_KEY = loaded_yamlfile['openai']['api_key']\n",
    "\n",
    "    return API_KEY\n",
    "\n",
    "# Call the function to get the API key\n",
    "openai.api_key = get_apikey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool 1: Does a query based search for Wikipages\n",
    "from typing import Any, List\n",
    "import wikipedia\n",
    "from llama_index import download_loader, VectorStoreIndex, ServiceContext\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.text_splitter import get_default_text_splitter\n",
    "import openai\n",
    "from pydantic import BaseModel\n",
    "from llama_index.program import OpenAIPydanticProgram\n",
    "from utils import get_apikey\n",
    "from typing import Callable, Dict, Optional, Union, List, Tuple, Any\n",
    "from llama_hub.wikipedia.base import WikipediaReader\n",
    "from llama_index import StorageContext\n",
    "from llama_index import load_index_from_storage\n",
    "import json\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "class WikiPediaPageName(BaseModel):\n",
    "    \"\"\"Data model for a Wikipedia Page.\"\"\"\n",
    "    page: str\n",
    "\n",
    "class WikiPageList(BaseModel):\n",
    "    \"Data model for WikiPageList\"\n",
    "    pages: List[WikiPediaPageName]\n",
    "\n",
    "def wikipage_list(wikipediapages):\n",
    "        openai.api_key = get_apikey()\n",
    "\n",
    "        prompt_template_str = \"\"\"\n",
    "        Given the input {query}, \n",
    "        return a list of Wikipedia page names.\n",
    "        \"\"\"\n",
    "        program = OpenAIPydanticProgram.from_defaults(\n",
    "            output_cls=WikiPageList,\n",
    "            prompt_template_str=prompt_template_str,\n",
    "            verbose=True,\n",
    "            llm=OpenAI(model=\"gpt-3.5-turbo-16k\")\n",
    "            \n",
    "        )\n",
    "        return program(query=wikipediapages)\n",
    "\n",
    "def search_wikipedia(\n",
    "        query: str, lang: str = \"en\", results_limit: int = 5, **load_kwargs: Any\n",
    "    ) -> List[List]:\n",
    "    wikipedia.set_lang(lang)\n",
    "    return wikipedia.search(query, results=results_limit)\n",
    "\n",
    "def create_wikidocs(wikipage_requests):\n",
    "    print(f\"Preparing to Download:{wikipage_requests}\")\n",
    "    WikipediaReader = download_loader(\"WikipediaReader\")\n",
    "    loader = WikipediaReader()\n",
    "    documents = loader.load_data(pages=wikipage_requests)\n",
    "    return documents\n",
    "\n",
    "def save_index(index) -> None:\n",
    "    index.storage_context.persist(index_path)\n",
    "\n",
    "def index_wikipedia_pages(wikipediapages: list):\n",
    "    global index\n",
    "    wikipage_requests = wikipage_list(wikipediapages)\n",
    "    documents = create_wikidocs(wikipage_requests)\n",
    "    text_splits = get_default_text_splitter(chunk_size=150, chunk_overlap=45)\n",
    "    parser = SimpleNodeParser.from_defaults(text_splitter=text_splits)\n",
    "    service_context = ServiceContext.from_defaults(node_parser=parser)\n",
    "    index =  VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "    save_index(index)\n",
    "\n",
    "def load_index(filepath: str):\n",
    "        # rebuild storage context\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=index_path)\n",
    "        # load index\n",
    "        return load_index_from_storage(storage_context)\n",
    "\n",
    "def read_json_file(file_path: str) -> dict:\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def query_vector_db(\n",
    "        search_string: str,\n",
    "        file_path = index_path,\n",
    "        n_results: int = 10\n",
    ") -> None: \n",
    "    index = load_index(filepath=index_path)\n",
    "    query_engine = index.as_query_engine(\n",
    "        response_mode=\"compact\", verbose=True, similarity_top_k=n_results\n",
    "    )\n",
    "    nodes = query_engine.query(search_string).source_nodes\n",
    "    retrieved_context = {\n",
    "        # \"ids\": [],\n",
    "        \"text\": []\n",
    "    }\n",
    "    for node in nodes:\n",
    "        # retrieved_context[\"ids\"].append(node.node.id_)\n",
    "        retrieved_context[\"text\"].append(node.node.text)\n",
    "    \n",
    "    file_path = index_path + \"retrieved_context.json\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(retrieved_context, f)\n",
    "    \n",
    "    return retrieved_context\n",
    "\n",
    "def generate_response(task:str):\n",
    "    openai.api_key = get_apikey()\n",
    "    context = read_json_file(index_path + \"retrieved_context.json\")\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",  \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": task},\n",
    "            {\"role\": \"assistant\", \"content\": f\"Use the information `{context}` to help you respond to the `{task}`\"}\n",
    "        ]\n",
    "    )\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"search_wikipedia\",\n",
    "            \"description\": \"Use this to search for relevant Wikipedia pages\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A query to search and identify relevant Wikipedia pages\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"name\": \"index_wikipedia_pages\",\n",
    "            \"description\": \"Use this to index wikipedia pages\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"wikipediapages\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The output of the search_wikipedia function\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"wikipediapages\"],\n",
    "            },\n",
    "        },\n",
    "\n",
    "        {\n",
    "            \"name\": \"query_vector_db\",\n",
    "            \"description\": \"Useful for retrieving relevant context from the index\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"search_string\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A query for which relevant context is required from the index\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"search_string\"],\n",
    "            },\n",
    "        },\n",
    "\n",
    "        {\n",
    "            \"name\": \"generate_response\",\n",
    "            \"description\": \"Useful to generate a response based on additional context provided by wikipedia search\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"task\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"task\": \"Your understanding of the task\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"task\"],\n",
    "            },\n",
    "        },\n",
    "        \n",
    "    ],\n",
    "    \"config_list\": config_list,\n",
    "    \"request_timeout\": 600,\n",
    "    \"seed\":43\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mwiki_bot\u001b[0m (to chat_manager):\n",
      "\n",
      "What was the first bank to fail in 2023 banking crisis?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwikisearch_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: search_wikipedia *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"query\": \"2023 banking crisis\"\n",
      "}\n",
      "\u001b[32m*****************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION search_wikipedia...\u001b[0m\n",
      "\u001b[33mwiki_bot\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"search_wikipedia\" *****\u001b[0m\n",
      "['2023 United States banking crisis', 'List of banking crises', '2007–2008 financial crisis', 'PacWest Bancorp', 'Ghana banking crisis']\n",
      "\u001b[32m*************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwikisearch_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: search_wikipedia *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"query\": \"2023 United States banking crisis\"\n",
      "}\n",
      "\u001b[32m*****************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION search_wikipedia...\u001b[0m\n",
      "\u001b[33mwiki_bot\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"search_wikipedia\" *****\u001b[0m\n",
      "['2023 United States banking crisis', 'List of banking crises', 'Banking in the United States', 'Acquisition of Credit Suisse by UBS', 'Ghana banking crisis']\n",
      "\u001b[32m*************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwikisearch_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: index_wikipedia_pages *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"wikipediapages\": \"2023 United States banking crisis\"\n",
      "}\n",
      "\u001b[32m**********************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION index_wikipedia_pages...\u001b[0m\n",
      "Function call: WikiPageList with args: {\n",
      "  \"pages\": [\n",
      "    {\n",
      "      \"page\": \"2023 United States banking crisis\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Preparing to Download:pages=[WikiPediaPageName(page='2023 United States banking crisis')]\n",
      "\u001b[33mwiki_bot\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"index_wikipedia_pages\" *****\u001b[0m\n",
      "None\n",
      "\u001b[32m******************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwikisearch_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "I couldn't find information about the first bank to fail in the 2023 banking crisis.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwikisearch_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: search_wikipedia *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"query\": \"bank failures in 2023\"\n",
      "}\n",
      "\u001b[32m*****************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION search_wikipedia...\u001b[0m\n",
      "\u001b[33mwiki_bot\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"search_wikipedia\" *****\u001b[0m\n",
      "['2023 United States banking crisis', 'Bank failure', 'List of largest bank failures in the United States', 'List of bank failures in the United States (2008–present)', 'Collapse of Silicon Valley Bank']\n",
      "\u001b[32m*************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-04 00:28:20] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a555a1cf45920b06fb94bcc9a5b46534 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a555a1cf45920b06fb94bcc9a5b46534 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a555a1cf45920b06fb94bcc9a5b46534 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:28:19 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '1234', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': 'a555a1cf45920b06fb94bcc9a5b46534', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208bc76380676de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a555a1cf45920b06fb94bcc9a5b46534 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a555a1cf45920b06fb94bcc9a5b46534 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a555a1cf45920b06fb94bcc9a5b46534 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:28:19 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '1234', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': 'a555a1cf45920b06fb94bcc9a5b46534', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208bc76380676de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 11-04 00:28:31] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 80315cf0bbe9b04785b654f21e575ff5 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 80315cf0bbe9b04785b654f21e575ff5 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 80315cf0bbe9b04785b654f21e575ff5 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:28:31 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '982', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': '80315cf0bbe9b04785b654f21e575ff5', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208bcbe3e5276de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 80315cf0bbe9b04785b654f21e575ff5 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 80315cf0bbe9b04785b654f21e575ff5 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 80315cf0bbe9b04785b654f21e575ff5 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:28:31 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '982', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': '80315cf0bbe9b04785b654f21e575ff5', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208bcbe3e5276de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 11-04 00:28:42] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 103e7fbb3b4e98b4ad06f61925d9d4bf in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 103e7fbb3b4e98b4ad06f61925d9d4bf in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 103e7fbb3b4e98b4ad06f61925d9d4bf in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:28:41 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '725', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': '103e7fbb3b4e98b4ad06f61925d9d4bf', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208bd048f1276de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 103e7fbb3b4e98b4ad06f61925d9d4bf in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 103e7fbb3b4e98b4ad06f61925d9d4bf in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 103e7fbb3b4e98b4ad06f61925d9d4bf in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:28:41 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '725', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': '103e7fbb3b4e98b4ad06f61925d9d4bf', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208bd048f1276de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 11-04 00:28:53] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID cddb850068dd7d16a72455718003dc23 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID cddb850068dd7d16a72455718003dc23 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID cddb850068dd7d16a72455718003dc23 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:28:52 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '708', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': 'cddb850068dd7d16a72455718003dc23', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208bd48ce6776de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID cddb850068dd7d16a72455718003dc23 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID cddb850068dd7d16a72455718003dc23 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID cddb850068dd7d16a72455718003dc23 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:28:52 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '708', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': 'cddb850068dd7d16a72455718003dc23', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208bd48ce6776de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 11-04 00:29:05] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 94ed72e8dfd35d68c260ef69866b2020 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 94ed72e8dfd35d68c260ef69866b2020 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 94ed72e8dfd35d68c260ef69866b2020 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:29:04 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '1215', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': '94ed72e8dfd35d68c260ef69866b2020', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208bd8cfcf276de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 94ed72e8dfd35d68c260ef69866b2020 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 94ed72e8dfd35d68c260ef69866b2020 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 94ed72e8dfd35d68c260ef69866b2020 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:29:04 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '1215', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': '94ed72e8dfd35d68c260ef69866b2020', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208bd8cfcf276de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 11-04 00:29:16] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID d2fd7616b86551a5f90b5a8d274e70d3 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID d2fd7616b86551a5f90b5a8d274e70d3 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID d2fd7616b86551a5f90b5a8d274e70d3 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:29:15 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '665', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': 'd2fd7616b86551a5f90b5a8d274e70d3', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208bdd47f4d76de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID d2fd7616b86551a5f90b5a8d274e70d3 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID d2fd7616b86551a5f90b5a8d274e70d3 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID d2fd7616b86551a5f90b5a8d274e70d3 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:29:15 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '665', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': 'd2fd7616b86551a5f90b5a8d274e70d3', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208bdd47f4d76de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 11-04 00:29:28] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 2b5cf40ea62e6729ad778d7c66b4d26b in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 2b5cf40ea62e6729ad778d7c66b4d26b in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 2b5cf40ea62e6729ad778d7c66b4d26b in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:29:27 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '2103', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': '2b5cf40ea62e6729ad778d7c66b4d26b', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208be184f0576de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 2b5cf40ea62e6729ad778d7c66b4d26b in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 2b5cf40ea62e6729ad778d7c66b4d26b in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 2b5cf40ea62e6729ad778d7c66b4d26b in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:29:27 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '2103', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': '2b5cf40ea62e6729ad778d7c66b4d26b', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208be184f0576de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 11-04 00:29:39] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID b46a5db177f435910dbbc3c31de722e4 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID b46a5db177f435910dbbc3c31de722e4 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID b46a5db177f435910dbbc3c31de722e4 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:29:38 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '809', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': 'b46a5db177f435910dbbc3c31de722e4', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208be659bbd76de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID b46a5db177f435910dbbc3c31de722e4 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID b46a5db177f435910dbbc3c31de722e4 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID b46a5db177f435910dbbc3c31de722e4 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:29:38 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '809', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': 'b46a5db177f435910dbbc3c31de722e4', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208be659bbd76de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 11-04 00:29:50] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID cf58c86384e1adfb083be58e44ce01ff in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID cf58c86384e1adfb083be58e44ce01ff in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID cf58c86384e1adfb083be58e44ce01ff in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:29:49 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '779', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': 'cf58c86384e1adfb083be58e44ce01ff', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208beaada4576de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID cf58c86384e1adfb083be58e44ce01ff in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID cf58c86384e1adfb083be58e44ce01ff in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID cf58c86384e1adfb083be58e44ce01ff in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:29:49 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '779', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': 'cf58c86384e1adfb083be58e44ce01ff', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208beaada4576de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 11-04 00:30:01] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 846c5f14c67158ff6e571b8d22e9b7af in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 846c5f14c67158ff6e571b8d22e9b7af in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 846c5f14c67158ff6e571b8d22e9b7af in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:30:00 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '702', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': '846c5f14c67158ff6e571b8d22e9b7af', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208beefc8ec76de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 846c5f14c67158ff6e571b8d22e9b7af in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 846c5f14c67158ff6e571b8d22e9b7af in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 846c5f14c67158ff6e571b8d22e9b7af in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:30:00 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '702', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': '846c5f14c67158ff6e571b8d22e9b7af', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208beefc8ec76de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 11-04 00:30:12] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID cb04f9f8985a05d38a902d8de97d9b66 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID cb04f9f8985a05d38a902d8de97d9b66 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID cb04f9f8985a05d38a902d8de97d9b66 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:30:11 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '675', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': 'cb04f9f8985a05d38a902d8de97d9b66', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208bf33ee5d76de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID cb04f9f8985a05d38a902d8de97d9b66 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID cb04f9f8985a05d38a902d8de97d9b66 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID cb04f9f8985a05d38a902d8de97d9b66 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:30:11 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '675', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': 'cb04f9f8985a05d38a902d8de97d9b66', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208bf33ee5d76de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 11-04 00:30:23] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 12b37e28e94b7e128f05552053754b82 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 12b37e28e94b7e128f05552053754b82 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 12b37e28e94b7e128f05552053754b82 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:30:22 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '658', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': '12b37e28e94b7e128f05552053754b82', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208bf77b9f076de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 12b37e28e94b7e128f05552053754b82 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 12b37e28e94b7e128f05552053754b82 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 12b37e28e94b7e128f05552053754b82 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:30:22 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '658', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': '12b37e28e94b7e128f05552053754b82', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208bf77b9f076de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 11-04 00:30:34] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 4a5f1ac28d4622168df7bdf28d2b9ab6 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 4a5f1ac28d4622168df7bdf28d2b9ab6 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 4a5f1ac28d4622168df7bdf28d2b9ab6 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:30:33 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '1005', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': '4a5f1ac28d4622168df7bdf28d2b9ab6', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208bfbc0da976de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 4a5f1ac28d4622168df7bdf28d2b9ab6 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 4a5f1ac28d4622168df7bdf28d2b9ab6 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 4a5f1ac28d4622168df7bdf28d2b9ab6 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:30:33 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '1005', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': '4a5f1ac28d4622168df7bdf28d2b9ab6', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208bfbc0da976de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 11-04 00:30:45] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 61df4236f0594b53856695f7a414e372 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 61df4236f0594b53856695f7a414e372 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 61df4236f0594b53856695f7a414e372 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:30:44 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '823', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': '61df4236f0594b53856695f7a414e372', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208c001f97176de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 61df4236f0594b53856695f7a414e372 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 61df4236f0594b53856695f7a414e372 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 61df4236f0594b53856695f7a414e372 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:30:44 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '823', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': '61df4236f0594b53856695f7a414e372', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208c001f97176de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 11-04 00:30:56] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 418d15e30bbf5f2fa24678ca1957f634 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 418d15e30bbf5f2fa24678ca1957f634 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 418d15e30bbf5f2fa24678ca1957f634 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:30:55 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '794', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179788', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': '418d15e30bbf5f2fa24678ca1957f634', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208c046eb3676de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 418d15e30bbf5f2fa24678ca1957f634 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 418d15e30bbf5f2fa24678ca1957f634 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 418d15e30bbf5f2fa24678ca1957f634 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:30:55 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '794', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179788', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': '418d15e30bbf5f2fa24678ca1957f634', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208c046eb3676de-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.completion: 11-04 00:31:07] {238} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 8bda1431151b69032ee621756e9c0149 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 8bda1431151b69032ee621756e9c0149 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 8bda1431151b69032ee621756e9c0149 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:31:07 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '790', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': '8bda1431151b69032ee621756e9c0149', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208c08efc6a6377-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py\", line 222, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"c:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 8bda1431151b69032ee621756e9c0149 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 8bda1431151b69032ee621756e9c0149 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 8bda1431151b69032ee621756e9c0149 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:31:07 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '790', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': '8bda1431151b69032ee621756e9c0149', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208c08efc6a6377-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py:222\u001b[0m, in \u001b[0;36mCompletion._get_response\u001b[1;34m(cls, config, raise_on_ratelimit_or_timeout, use_cache)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mrequest_timeout\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config:\n\u001b[1;32m--> 222\u001b[0m     response \u001b[39m=\u001b[39m openai_completion\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig)\n\u001b[0;32m    223\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    140\u001b[0m (\n\u001b[0;32m    141\u001b[0m     deployment_id,\n\u001b[0;32m    142\u001b[0m     engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m     api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    153\u001b[0m )\n\u001b[1;32m--> 155\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    156\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    157\u001b[0m     url,\n\u001b[0;32m    158\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    159\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    160\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    161\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    162\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    163\u001b[0m )\n\u001b[0;32m    165\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    166\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    289\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    290\u001b[0m     method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    291\u001b[0m     url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m     request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    298\u001b[0m )\n\u001b[1;32m--> 299\u001b[0m resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    300\u001b[0m \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    715\u001b[0m         ),\n\u001b[0;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    717\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\openai\\api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    777\u001b[0m     )\n\u001b[0;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mAPIError\u001b[0m: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 8bda1431151b69032ee621756e9c0149 in your email.) {\n  \"error\": {\n    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 8bda1431151b69032ee621756e9c0149 in your email.)\",\n    \"type\": \"server_error\",\n    \"param\": null,\n    \"code\": null\n  }\n}\n 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 8bda1431151b69032ee621756e9c0149 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 04 Nov 2023 00:31:07 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-16k-0613', 'openai-organization': 'user-o32o8oehynmyzpauk2oqjtyt', 'openai-processing-ms': '790', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '180000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '179787', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '70ms', 'x-request-id': '8bda1431151b69032ee621756e9c0149', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8208c08efc6a6377-LHR', 'alt-svc': 'h3=\":443\"; ma=86400'}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mg:\\My Drive\\Data-Centric Solutions\\07. Blog Posts\\AutoGen\\autogen_tutorial\\autogen_tutorial.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Data-Centric%20Solutions/07.%20Blog%20Posts/AutoGen/autogen_tutorial/autogen_tutorial.ipynb#X40sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m groupchat \u001b[39m=\u001b[39m autogen\u001b[39m.\u001b[39mGroupChat(agents\u001b[39m=\u001b[39m[wiki_bot, wikisearch_agent, wiki_index_agent, retrieve_agent, response_agent], messages\u001b[39m=\u001b[39m[], max_round\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Data-Centric%20Solutions/07.%20Blog%20Posts/AutoGen/autogen_tutorial/autogen_tutorial.ipynb#X40sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m manager \u001b[39m=\u001b[39m autogen\u001b[39m.\u001b[39mGroupChatManager(groupchat\u001b[39m=\u001b[39mgroupchat, llm_config\u001b[39m=\u001b[39mllm_config)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/My%20Drive/Data-Centric%20Solutions/07.%20Blog%20Posts/AutoGen/autogen_tutorial/autogen_tutorial.ipynb#X40sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m wiki_bot\u001b[39m.\u001b[39;49minitiate_chat(manager, message\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mWhat was the first bank to fail in 2023 banking crisis?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:531\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[1;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \n\u001b[0;32m    519\u001b[0m \u001b[39mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[1;32m--> 531\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_init_message(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcontext), recipient, silent\u001b[39m=\u001b[39;49msilent)\n",
      "File \u001b[1;32mc:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:334\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    332\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[1;32m--> 334\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[0;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    337\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    338\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:462\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 462\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_messages[sender], sender\u001b[39m=\u001b[39;49msender)\n\u001b[0;32m    463\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender, silent\u001b[39m=\u001b[39msilent)\n",
      "File \u001b[1;32mc:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:781\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[1;32m--> 781\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, config\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    782\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[0;32m    783\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[1;32mc:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\agentchat\\groupchat.py:164\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    162\u001b[0m     speaker \u001b[39m=\u001b[39m groupchat\u001b[39m.\u001b[39mselect_speaker(speaker, \u001b[39mself\u001b[39m)\n\u001b[0;32m    163\u001b[0m     \u001b[39m# let the speaker speak\u001b[39;00m\n\u001b[1;32m--> 164\u001b[0m     reply \u001b[39m=\u001b[39m speaker\u001b[39m.\u001b[39;49mgenerate_reply(sender\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    165\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m    166\u001b[0m     \u001b[39m# let the admin agent speak if interrupted\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m groupchat\u001b[39m.\u001b[39madmin_name \u001b[39min\u001b[39;00m groupchat\u001b[39m.\u001b[39magent_names:\n\u001b[0;32m    168\u001b[0m         \u001b[39m# admin agent is one of the participants\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:781\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[1;32m--> 781\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, config\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    782\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[0;32m    783\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[1;32mc:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:606\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    603\u001b[0m     messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_oai_messages[sender]\n\u001b[0;32m    605\u001b[0m \u001b[39m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[1;32m--> 606\u001b[0m response \u001b[39m=\u001b[39m oai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mcreate(\n\u001b[0;32m    607\u001b[0m     context\u001b[39m=\u001b[39mmessages[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m), messages\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_oai_system_message \u001b[39m+\u001b[39m messages, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mllm_config\n\u001b[0;32m    608\u001b[0m )\n\u001b[0;32m    609\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m, oai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mextract_text_or_function_call(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py:803\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, context, use_cache, config_list, filter_func, raise_on_ratelimit_or_timeout, allow_format_str_template, **config)\u001b[0m\n\u001b[0;32m    801\u001b[0m     base_config[\u001b[39m\"\u001b[39m\u001b[39mmax_retry_period\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 803\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcreate(\n\u001b[0;32m    804\u001b[0m         context,\n\u001b[0;32m    805\u001b[0m         use_cache,\n\u001b[0;32m    806\u001b[0m         raise_on_ratelimit_or_timeout\u001b[39m=\u001b[39mi \u001b[39m<\u001b[39m last \u001b[39mor\u001b[39;00m raise_on_ratelimit_or_timeout,\n\u001b[0;32m    807\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbase_config,\n\u001b[0;32m    808\u001b[0m     )\n\u001b[0;32m    809\u001b[0m     \u001b[39mif\u001b[39;00m response \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[0;32m    810\u001b[0m         \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py:834\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, context, use_cache, config_list, filter_func, raise_on_ratelimit_or_timeout, allow_format_str_template, **config)\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[39mwith\u001b[39;00m diskcache\u001b[39m.\u001b[39mCache(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcache_path) \u001b[39mas\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_cache:\n\u001b[0;32m    833\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mset_cache(seed)\n\u001b[1;32m--> 834\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_response(params, raise_on_ratelimit_or_timeout\u001b[39m=\u001b[39;49mraise_on_ratelimit_or_timeout)\n",
      "File \u001b[1;32mc:\\Users\\johna\\anaconda3\\envs\\autogen_env\\lib\\site-packages\\autogen\\oai\\completion.py:239\u001b[0m, in \u001b[0;36mCompletion._get_response\u001b[1;34m(cls, config, raise_on_ratelimit_or_timeout, use_cache)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[39m# transient error\u001b[39;00m\n\u001b[0;32m    238\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mretrying in \u001b[39m\u001b[39m{\u001b[39;00mretry_wait_time\u001b[39m}\u001b[39;00m\u001b[39m seconds...\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 239\u001b[0m     sleep(retry_wait_time)\n\u001b[0;32m    240\u001b[0m \u001b[39mexcept\u001b[39;00m (RateLimitError, Timeout) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    241\u001b[0m     time_left \u001b[39m=\u001b[39m max_retry_period \u001b[39m-\u001b[39m (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time \u001b[39m+\u001b[39m retry_wait_time)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import autogen \n",
    "wiki_bot = autogen.UserProxyAgent(\n",
    "    name=\"wiki_bot\",\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=5,\n",
    "    system_message= \"Your job is to guide agents towards completing the task\",\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "wikisearch_agent = autogen.AssistantAgent(\n",
    "    name=\"wikisearch_agent\",\n",
    "    system_message=\"Your job is to search for the titles of relevant Wikipedia pages.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "wiki_index_agent = autogen.AssistantAgent(\n",
    "    name=\"wiki_index_agent\",\n",
    "    system_message=\"Your job is to index the relevant wikipedia pages from the titles provided by wikisearch_agent.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "retrieve_agent = autogen.AssistantAgent(\n",
    "    name=\"retrieve_agent\",\n",
    "    system_message=\"Your job is to retrieve relevant information from the index.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "response_agent = autogen.AssistantAgent(\n",
    "    name=\"response_agent\",\n",
    "    system_message=\"Your job is to generate a response to the task based using the generate_response tool.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "wiki_bot.register_function(\n",
    "    function_map={\n",
    "        \"search_wikipedia\": search_wikipedia,\n",
    "        \"index_wikipedia_pages\":index_wikipedia_pages,\n",
    "        \"query_vector_db\":query_vector_db,\n",
    "        \"generate_response\":generate_response\n",
    "    }\n",
    ")\n",
    "\n",
    "groupchat = autogen.GroupChat(agents=[wiki_bot, wikisearch_agent, wiki_index_agent, retrieve_agent, response_agent], messages=[], max_round=20)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n",
    "wiki_bot.initiate_chat(manager, message=\"What was the first bank to fail in 2023 banking crisis?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
